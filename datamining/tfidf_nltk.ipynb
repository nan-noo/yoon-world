{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from khaiii import KhaiiiApi\n",
    "from gensim import corpora, models\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [i for i in range(1997, 2021)]\n",
    "sortedresult = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==== 1997 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  71\n",
      "# documents :  10\n",
      "==== calculating tfidf ====\n",
      "   year    교육    연구   cai    자료  web    개별  멀티미디어    원격   편집기  ...    자기  \\\n",
      "0  1997  1.02  0.82  0.81  0.78  0.7  0.68   0.66  0.66  0.66  ...  0.11   \n",
      "\n",
      "    서비스    일선    원인    연결   안내자    실정   시스템    다양    학생  \n",
      "0  0.11  0.11  0.11  0.11  0.11  0.11  0.11  0.11  0.11  \n",
      "\n",
      "[1 rows x 72 columns]\n",
      "==== completed ====\n",
      "==== 1998 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  457\n",
      "# documents :  34\n",
      "==== calculating tfidf ====\n",
      "   year    교육    정보  에이전트   시스템    설계    연구   컴퓨터  소프트웨어    초등  ...   베이스  \\\n",
      "0  1998  2.24  1.72   1.6  1.58  1.37  1.33  1.29   1.24  1.22  ...  0.06   \n",
      "\n",
      "     선정  시뮬레이션  시물레이션  dijkstra  modified    도로   디지털    소요    실용  \n",
      "0  0.06   0.06   0.06      0.06      0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 458 columns]\n",
      "==== completed ====\n",
      "==== 1999 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  484\n",
      "# documents :  25\n",
      "==== calculating tfidf ====\n",
      "   year   정보    교육    학습    검색   시스템   컴퓨터   인터넷    문화    실습  ...    극치    분리  \\\n",
      "0  1999  1.4  1.29  1.25  1.11  1.05  0.98  0.87  0.85  0.83  ...  0.05  0.05   \n",
      "\n",
      "     좌표    증대  최소자숭법    행렬    모듈    기대   근사치   두과정  \n",
      "0  0.05  0.05   0.05  0.05  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 485 columns]\n",
      "==== completed ====\n",
      "==== 2000 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  454\n",
      "# documents :  22\n",
      "==== calculating tfidf ====\n",
      "   year    학습    평가    그룹  코스웨어   학습자   컴퓨터    정보    설계    활동  ...    담당  \\\n",
      "0  2000  1.95  1.19  1.03  1.02  0.98  0.84  0.84  0.81  0.81  ...  0.06   \n",
      "\n",
      "     현실    재정    요인    실태    실시    설문    빈도    기초    저해  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 455 columns]\n",
      "==== completed ====\n",
      "==== 2001 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  681\n",
      "# documents :  33\n",
      "==== calculating tfidf ====\n",
      "   year    평가    활용    정보  프로그래밍   학습자   컴퓨터    학습    게임   인터넷  ...    부각  \\\n",
      "0  2001  1.55  1.53  1.51    1.4  1.31  1.29  1.27  1.27  1.26  ...  0.07   \n",
      "\n",
      "     형식   해결력    질적    고민    비판    단체    단회   두려움   면대면  \n",
      "0  0.07  0.07  0.07  0.07  0.07  0.07  0.07  0.07  0.07  \n",
      "\n",
      "[1 rows x 682 columns]\n",
      "==== completed ====\n",
      "==== 2002 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  641\n",
      "# documents :  33\n",
      "==== calculating tfidf ====\n",
      "   year  프로젝트   학습   학습자    주도    문제    모형    중심    교육   시스템  ...    동시    동안  \\\n",
      "0  2002  2.35  1.5  1.37  1.28  1.26  1.21  1.19  1.16  1.15  ...  0.07  0.07   \n",
      "\n",
      "     모양    발견    소리   아동감   아래쪽   감상문   성취감   자신감  \n",
      "0  0.07  0.07  0.07  0.07  0.07  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 642 columns]\n",
      "==== completed ====\n",
      "==== 2003 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  684\n",
      "# documents :  34\n",
      "==== calculating tfidf ====\n",
      "   year    학습    상담    환경    평가    교수   학습자   시스템   ict    정보  ...    정신  \\\n",
      "0  2003  1.47  1.45  1.43  1.37  1.31  1.28  1.09  1.06  1.06  ...  0.05   \n",
      "\n",
      "     보완    허용    여건    편안    충족   분위기    유리   거부감    제약  \n",
      "0  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 685 columns]\n",
      "==== completed ====\n",
      "==== 2004 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  890\n",
      "# documents :  50\n",
      "==== calculating tfidf ====\n",
      "   year   학습   컴퓨터    통신   정보    상담  학습자   ict    활용    평가  ...    이종  온톨로지  \\\n",
      "0  2004  2.7  2.48  2.12  1.9  1.88  1.8  1.76  1.68  1.59  ...  0.07  0.07   \n",
      "\n",
      "    연구자    연관    연결    시기   스키마    선행    반의   부족량  \n",
      "0  0.07  0.07  0.07  0.07  0.07  0.07  0.07  0.07  \n",
      "\n",
      "[1 rows x 891 columns]\n",
      "==== completed ====\n",
      "==== 2005 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  995\n",
      "# documents :  58\n",
      "==== calculating tfidf ====\n",
      "   year    영재   평가    학습   컴퓨터    과학    정보    교육   ict    활용  ...    경력   평균치  \\\n",
      "0  2005  2.67  2.5  2.44  2.32  1.97  1.97  1.83  1.72  1.66  ...  0.04  0.04   \n",
      "\n",
      "     간접    남녀    수도    신체    요약    해석    친구  집단사이  \n",
      "0  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 996 columns]\n",
      "==== completed ====\n",
      "==== 2006 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  810\n",
      "# documents :  40\n",
      "==== calculating tfidf ====\n",
      "   year    로봇   컴퓨터    정보    수업    학습  교과서   ict    평가   교육  ...   선호도    수치  \\\n",
      "0  2006  2.11  2.01  1.88  1.78  1.74  1.5  1.48  1.43  1.4  ...  0.06  0.06   \n",
      "\n",
      "     아이    우수    타원    신체   보충형  보충학습용    대인   가이드  \n",
      "0  0.06  0.06  0.06  0.06  0.06   0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 811 columns]\n",
      "==== completed ====\n",
      "==== 2007 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  953\n",
      "# documents :  49\n",
      "==== calculating tfidf ====\n",
      "   year    학습   시스템   컴퓨터    정보    게임    로봇    토론  프로그래밍    학교  ...   교정자  \\\n",
      "0  2007  2.02  1.96  1.94  1.89  1.87  1.86  1.56   1.46  1.45  ...  0.06   \n",
      "\n",
      "    드로잉   변경시  html    원본   전자펜    위배  context  ambiguity  컨텍스트  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.06     0.06       0.06  0.06  \n",
      "\n",
      "[1 rows x 954 columns]\n",
      "==== completed ====\n",
      "==== 2008 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  868\n",
      "# documents :  45\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍   컴퓨터    평가   정보   시스템    초등    학습    로봇    윤리  ...    인재  \\\n",
      "0  2008   2.56  1.92  1.91  1.8  1.79  1.35  1.34  1.33  1.24  ...  0.06   \n",
      "\n",
      "    분류표    대외    근본    방지    범죄    설정  윤리의식   인식도    행위  \n",
      "0  0.06  0.06  0.04  0.04  0.04  0.04  0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 869 columns]\n",
      "==== completed ====\n",
      "==== 2009 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  892\n",
      "# documents :  50\n",
      "==== calculating tfidf ====\n",
      "   year   사이버    로봇    학습  프로그래밍    정보    수업   정학습    교육   컴퓨터  ...    충족  \\\n",
      "0  2009  2.01  1.94  1.81   1.77  1.51  1.51  1.41  1.39  1.38  ...  0.06   \n",
      "\n",
      "     투입    파급  issct  isst   공교육    궁극    요령    회복    정체  \n",
      "0  0.06  0.06   0.06  0.06  0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 893 columns]\n",
      "==== completed ====\n",
      "==== 2010 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  984\n",
      "# documents :  62\n",
      "==== calculating tfidf ====\n",
      "   year    로봇  프로그래밍    학습    정보   문제   시스템   컴퓨터  프로그램    게임  ...    표준  \\\n",
      "0  2010  3.18   2.99  2.66  2.14  1.9  1.88  1.85  1.72  1.64  ...  0.06   \n",
      "\n",
      "     규격   통신망    타인    정립    고취    별도   가이드    제언    소지  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 985 columns]\n",
      "==== completed ====\n",
      "==== 2011 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  1018\n",
      "# documents :  63\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍    로봇    학습    정보    영재    과학    저작  스크래치  프로그램  ...    평생  \\\n",
      "0  2011   3.94  2.93  2.67  2.58  2.27  2.12  1.81  1.81  1.76  ...  0.06   \n",
      "\n",
      "     조금  커리큘럼    홍보    간접  구조방정식모형    유일    각급    재학    인과  \n",
      "0  0.06  0.06  0.06  0.06     0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 1019 columns]\n",
      "==== completed ====\n",
      "==== 2012 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  912\n",
      "# documents :  49\n",
      "==== calculating tfidf ====\n",
      "   year    정보    로봇  프로그래밍   스마트    학습    현실  알고리즘    증강   학습자  ...    여성  \\\n",
      "0  2012  2.37  2.13   2.12  1.97  1.85  1.66  1.65  1.53  1.46  ...  0.05   \n",
      "\n",
      "     어촌    수요    소외    성비    농산    남성    기피    균형    사상  \n",
      "0  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 913 columns]\n",
      "==== completed ====\n",
      "==== 2013 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  903\n",
      "# documents :  48\n",
      "==== calculating tfidf ====\n",
      "   year    로봇  steam    학습  프로그래밍   컴퓨터   스마트    정보  프로그램    개발  ...    표정  \\\n",
      "0  2013  2.99   2.39  1.97    1.9  1.75  1.58  1.43   1.4  1.35  ...  0.06   \n",
      "\n",
      "    카메라    추후  교수학습   경기도   재학생    수과    여가    보통  영재캠프  \n",
      "0  0.06  0.06  0.06  0.05  0.05  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 904 columns]\n",
      "==== completed ====\n",
      "==== 2014 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  946\n",
      "# documents :  63\n",
      "==== calculating tfidf ====\n",
      "   year    로봇  프로그래밍    정보   컴퓨터    과학    학습    게임    내용  스마트폰  ...    저작  \\\n",
      "0  2014  3.89   3.86  3.26  2.67  2.48  2.28  2.26  2.05  2.01  ...  0.04   \n",
      "\n",
      "     밀접    부분    한계    역할    총괄   책임자    지휘    지정    면담  \n",
      "0  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 947 columns]\n",
      "==== completed ====\n",
      "==== 2015 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  937\n",
      "# documents :  53\n",
      "==== calculating tfidf ====\n",
      "   year    sw  프로그래밍    로봇  소프트웨어  디지털교과서    학습    수업    정보  알고리즘  ...    주중  \\\n",
      "0  2015  2.71   2.69  2.07   2.06     2.0  1.86  1.81  1.73  1.73  ...  0.03   \n",
      "\n",
      "     처음    염려    현황   월평균    오후    오전    영유    영아   이용자  \n",
      "0  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  \n",
      "\n",
      "[1 rows x 938 columns]\n",
      "==== completed ====\n",
      "==== 2016 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  989\n",
      "# documents :  64\n",
      "==== calculating tfidf ====\n",
      "   year    정보    sw  프로그래밍   컴퓨팅    교사    활동    과정  컴퓨터  알고리즘  ...    발현  \\\n",
      "0  2016  2.84  2.52   2.49  2.21  2.17  2.16  2.15  2.1  2.04  ...  0.06   \n",
      "\n",
      "    분별력    구별   과부하   결과물    조망    단점    연습    전이   초보자  \n",
      "0  0.06  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 990 columns]\n",
      "==== completed ====\n",
      "==== 2017 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  969\n",
      "# documents :  68\n",
      "==== calculating tfidf ====\n",
      "   year    sw  프로그래밍   ict   정보   컴퓨팅  소프트웨어   학습    로봇   교사  ...   계획서    각각  \\\n",
      "0  2017  3.33   2.76  2.74  2.6  2.56    2.3  2.3  2.11  2.1  ...  0.06  0.06   \n",
      "\n",
      "    통제력    차년  종단연구    정식  자기주도학습    일관    여가    편차  \n",
      "0  0.06  0.06  0.06  0.06    0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 970 columns]\n",
      "==== completed ====\n",
      "==== 2018 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  1031\n",
      "# documents :  69\n",
      "==== calculating tfidf ====\n",
      "   year    로봇    sw    교사   컴퓨팅    학습    교수  가상현실    예비  프로그래밍  ...    검토  \\\n",
      "0  2018  3.05  3.02  2.73  2.66  2.44  2.21  2.11  2.09   2.01  ...  0.07   \n",
      "\n",
      "     합리  educational    제기    자유    인공    시점  resource   oer  access  \n",
      "0  0.07         0.06  0.06  0.06  0.06  0.06      0.06  0.06    0.06  \n",
      "\n",
      "[1 rows x 1032 columns]\n",
      "==== completed ====\n",
      "==== 2019 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  957\n",
      "# documents :  66\n",
      "==== calculating tfidf ====\n",
      "   year  인공지능  컴퓨팅    sw   사고력   메이커  프로그램    학습    교사  언플러그드  ...    일자  \\\n",
      "0  2019  3.12  2.9  2.81  2.71  2.69  2.62  2.32  2.17    2.1  ...  0.06   \n",
      "\n",
      "     일정  임베디드    결국    작동   저전력    간격   전력량    전송    특화  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 958 columns]\n",
      "==== completed ====\n",
      "==== 2020 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  928\n",
      "# documents :  47\n",
      "==== calculating tfidf ====\n",
      "   year    ai  인공지능    sw   사고력    로봇    평가   컴퓨팅    초등  프로그래밍  ...   운영자  \\\n",
      "0  2020  3.24  2.44  2.27  2.09  2.09  1.95  1.69  1.58   1.52  ...  0.05   \n",
      "\n",
      "     심층   스스로    건강    본격    기록    기획    반면    대신    담당  \n",
      "0  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 929 columns]\n",
      "==== completed ====\n"
     ]
    }
   ],
   "source": [
    "for i in range(24):\n",
    "    print(\"==== \"+str(year[i])+\" ====\")\n",
    "    data = pd.read_csv(\"./modi_data/kor_\"+str(year[i])+\".csv\")\n",
    "    #data = data.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "    dfWordList = pd.read_excel(\"./khaiii_word_cor.xlsx\")\n",
    "    dfWordList2 = pd.read_excel(\"./khaiii_word_cor_etc.xlsx\")\n",
    "    #print(dfWordList2)\n",
    "\n",
    "    dfWordDel = dfWordList[dfWordList[\"수정\"] == \"삭제\"]\n",
    "    dfWordMod = dfWordList[dfWordList[\"수정\"] != \"삭제\"]\n",
    "    dfWordDiv = dfWordList2\n",
    "    #print(dfWordMod)\n",
    "\n",
    "    seriesDelete = dfWordDel[\"기존\"]\n",
    "    stopword = []\n",
    "    for word in seriesDelete.values:\n",
    "        stopword.append(word)\n",
    "    #print(stopword)\n",
    "\n",
    "    seriesModify = dfWordMod[\"기존\"]\n",
    "    modiword = []\n",
    "    for word in seriesModify.values:\n",
    "        modiword.append(word)\n",
    "    #print(len(modiword))\n",
    "\n",
    "    seriesModify2 = dfWordMod[\"수정\"]\n",
    "    modiword2 = []\n",
    "    for word in seriesModify2.values:\n",
    "        modiword2.append(word)\n",
    "    #print(len(modiword2))\n",
    "\n",
    "    seriesDivide = dfWordDiv[\"기존\"]\n",
    "    divword = []\n",
    "    for word in seriesDivide.values:\n",
    "        divword.append(word)\n",
    "    #print(divword)\n",
    "    #print(len(divword))\n",
    "\n",
    "    seriesDivide2 = dfWordDiv[\"수정\"]\n",
    "    divword2 = []\n",
    "    for words in seriesDivide2.values:\n",
    "        divword2.append(words.split(', '))\n",
    "    #print(divword2)\n",
    "    #print(len(divword2))\n",
    "\n",
    "\n",
    "    api = KhaiiiApi()\n",
    "    def khaiiiTokenizer(raw, stopword=stopword, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL']): # 일반명사 고유명사 의존명사 대명사 수사 외국어\n",
    "        list = []\n",
    "        skip = 0\n",
    "\n",
    "        for word in api.analyze(raw): #raw data\n",
    "            #print(word)\n",
    "            \n",
    "            for i, morph in enumerate(word.morphs):\n",
    "                #print(morph.lex)\n",
    "                if skip == 1: \n",
    "                    #print(morph.lex) # '지능'\n",
    "                    skip = 0\n",
    "                    continue\n",
    "\n",
    "                if morph.lex == '인공' and i+1 < len(word.morphs) and word.morphs[i+1].lex == \"지능\":\n",
    "                    #print(morph.lex + word.morphs[i+1].lex) # 인공지능\n",
    "                    list.append(morph.lex + word.morphs[i+1].lex)\n",
    "                    skip = 1\n",
    "                    continue\n",
    "\n",
    "                if len(morph.lex) > 1 and morph.tag in pos and morph.lex not in stopword: \n",
    "                    if morph.tag == 'SL':\n",
    "                        morph.lex = morph.lex.lower()\n",
    "                    if morph.lex in divword:\n",
    "                        morph.lex = divword2[divword.index(morph.lex)]\n",
    "                        list.extend(morph.lex)\n",
    "                    elif morph.lex in modiword:\n",
    "                        morph.lex = modiword2[modiword.index(morph.lex)]\n",
    "                        list.append(morph.lex)\n",
    "                    else: list.append(morph.lex)\n",
    "                    \n",
    "        return list\n",
    "\n",
    "    tokenized = data[\"kor_full\"].apply(lambda row: khaiiiTokenizer(row))\n",
    "    #print(tokenized)\n",
    "    #tokenized.to_excel(\"./finaldata/0911token_full.xls\") ##############\n",
    "    print(\"========= tokenization completed =========\")\n",
    "\n",
    "    id2word = corpora.Dictionary(tokenized)\n",
    "    corpus=[id2word.doc2bow(text) for text in tokenized]\n",
    "    print(\"# words in total : \", len(id2word))\n",
    "    print(\"# documents : \", len(corpus))\n",
    "\n",
    "    #tfidf\n",
    "    print(\"==== calculating tfidf ====\")\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "    #tfidf per doc\n",
    "    tfidflist = []\n",
    "    for doc in tfidf[corpus]:\n",
    "        inner_list = [0]*len(id2word) \n",
    "        for id, freq in doc:\n",
    "            inner_list[id] = np.around(freq, decimals=2) #put tfidf value in the place matching its index\n",
    "        tfidflist.append(inner_list)\n",
    "    #print(len(tfidflist))\n",
    "\n",
    "    tfidf_df = pd.DataFrame(tfidflist)\n",
    "    tfidf_df.columns = [id2word[i] for i in range(len(id2word))] #set columns' names as words\n",
    "    #print(tfidf_df)\n",
    "\n",
    "    total_df = pd.concat([data[[\"year\", \"no\"]], tfidf_df], axis=1)\n",
    "    #print(total_df)\n",
    "    total_df.to_excel(\"./final_data/tfidf\"+str(year[i])+\".xlsx\") \n",
    "\n",
    "    #sum of tfidf for each word\n",
    "    columnsum = pd.DataFrame(total_df.sum(axis=0)).T\n",
    "    columnsum = columnsum.drop(['no'], axis=1)\n",
    "    columnsum['year'] = year[i]\n",
    "    #print(columnsum)\n",
    "    columnsum.to_excel(\"./final_data/sum\"+str(year[i])+\".xlsx\")\n",
    "\n",
    "    #sort tfidf value in descending order\n",
    "    columnsum = columnsum.sort_values(by=0, axis=1, ascending=False)\n",
    "    print(columnsum)\n",
    "    columnsum.to_excel(\"./final_data/sorted\"+str(year[i])+\".xlsx\")\n",
    "\n",
    "    print(\"==== completed ====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========= tokenization completed =========\n",
      "# words in total :  5086\n",
      "# documents :  1149\n",
      "==== calculating tfidf ====\n",
      "   year     학습  프로그래밍     정보     로봇    컴퓨터    시스템     교육     sw     평가  ...  \\\n",
      "0  2020  38.82  36.43  36.23  33.03  31.51  28.13  26.34  25.67  25.39  ...   \n",
      "\n",
      "    양육자    소득    가계    영유    오전    오후    장르    주말    주중    영아  \n",
      "0  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 5087 columns]\n",
      "==== completed ====\n"
     ]
    }
   ],
   "source": [
    "# tfidf for full data\n",
    "\n",
    "data = pd.read_csv(\"./modi_data/kor_full.csv\")\n",
    "#data = data.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "dfWordList = pd.read_excel(\"./khaiii_word_cor.xlsx\")\n",
    "dfWordList2 = pd.read_excel(\"./khaiii_word_cor_etc.xlsx\")\n",
    "#print(dfWordList2)\n",
    "\n",
    "dfWordDel = dfWordList[dfWordList[\"수정\"] == \"삭제\"]\n",
    "dfWordMod = dfWordList[dfWordList[\"수정\"] != \"삭제\"]\n",
    "dfWordDiv = dfWordList2\n",
    "#print(dfWordMod)\n",
    "\n",
    "seriesDelete = dfWordDel[\"기존\"]\n",
    "stopword = []\n",
    "for word in seriesDelete.values:\n",
    "    stopword.append(word)\n",
    "#print(stopword)\n",
    "\n",
    "seriesModify = dfWordMod[\"기존\"]\n",
    "modiword = []\n",
    "for word in seriesModify.values:\n",
    "    modiword.append(word)\n",
    "#print(len(modiword))\n",
    "\n",
    "seriesModify2 = dfWordMod[\"수정\"]\n",
    "modiword2 = []\n",
    "for word in seriesModify2.values:\n",
    "    modiword2.append(word)\n",
    "#print(len(modiword2))\n",
    "\n",
    "seriesDivide = dfWordDiv[\"기존\"]\n",
    "divword = []\n",
    "for word in seriesDivide.values:\n",
    "    divword.append(word)\n",
    "#print(divword)\n",
    "#print(len(divword))\n",
    "\n",
    "seriesDivide2 = dfWordDiv[\"수정\"]\n",
    "divword2 = []\n",
    "for words in seriesDivide2.values:\n",
    "    divword2.append(words.split(', '))\n",
    "#print(divword2)\n",
    "#print(len(divword2))\n",
    "\n",
    "\n",
    "api = KhaiiiApi()\n",
    "def khaiiiTokenizer(raw, stopword=stopword, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL']): # 일반명사 고유명사 의존명사 대명사 수사 외국어\n",
    "    list = []\n",
    "    skip = 0\n",
    "\n",
    "    for word in api.analyze(raw): #raw data\n",
    "        #print(word)\n",
    "        \n",
    "        for i, morph in enumerate(word.morphs):\n",
    "            #print(morph.lex)\n",
    "            if skip == 1: \n",
    "                #print(morph.lex) # '지능'\n",
    "                skip = 0\n",
    "                continue\n",
    "\n",
    "            if morph.lex == '인공' and i+1 < len(word.morphs) and word.morphs[i+1].lex == \"지능\":\n",
    "                #print(morph.lex + word.morphs[i+1].lex) # 인공지능\n",
    "                list.append(morph.lex + word.morphs[i+1].lex)\n",
    "                skip = 1\n",
    "                continue\n",
    "\n",
    "            if len(morph.lex) > 1 and morph.tag in pos and morph.lex not in stopword: \n",
    "                if morph.tag == 'SL':\n",
    "                    morph.lex = morph.lex.lower()\n",
    "                if morph.lex in divword:\n",
    "                    morph.lex = divword2[divword.index(morph.lex)]\n",
    "                    list.extend(morph.lex)\n",
    "                elif morph.lex in modiword:\n",
    "                    morph.lex = modiword2[modiword.index(morph.lex)]\n",
    "                    list.append(morph.lex)\n",
    "                else: list.append(morph.lex)\n",
    "                \n",
    "    return list\n",
    "\n",
    "tokenized = data[\"kor_full\"].apply(lambda row: khaiiiTokenizer(row))\n",
    "#print(tokenized)\n",
    "#tokenized.to_excel(\"./finaldata/0911token_full.xls\") ##############\n",
    "print(\"========= tokenization completed =========\")\n",
    "\n",
    "id2word = corpora.Dictionary(tokenized)\n",
    "corpus=[id2word.doc2bow(text) for text in tokenized]\n",
    "print(\"# words in total : \", len(id2word))\n",
    "print(\"# documents : \", len(corpus))\n",
    "\n",
    "#tfidf\n",
    "print(\"==== calculating tfidf ====\")\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "#tfidf per doc\n",
    "tfidflist = []\n",
    "for doc in tfidf[corpus]:\n",
    "    inner_list = [0]*len(id2word) \n",
    "    for id, freq in doc:\n",
    "        inner_list[id] = np.around(freq, decimals=2) #put tfidf value in the place matching its index\n",
    "    tfidflist.append(inner_list)\n",
    "#print(len(tfidflist))\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidflist)\n",
    "tfidf_df.columns = [id2word[i] for i in range(len(id2word))] #set columns' names as words\n",
    "#print(tfidf_df)\n",
    "\n",
    "total_df = pd.concat([data[[\"year\", \"no\"]], tfidf_df], axis=1)\n",
    "#print(total_df)\n",
    "total_df.to_excel(\"./final_data/tfidf_full.xlsx\") \n",
    "\n",
    "#sum of tfidf for each word\n",
    "columnsum = pd.DataFrame(total_df.sum(axis=0)).T\n",
    "columnsum = columnsum.drop(['no'], axis=1)\n",
    "columnsum['year'] = year[i]\n",
    "#print(columnsum)\n",
    "columnsum.to_excel(\"./final_data/sum_full.xlsx\")\n",
    "\n",
    "#sort tfidf value in descending order\n",
    "columnsum = columnsum.sort_values(by=0, axis=1, ascending=False)\n",
    "print(columnsum)\n",
    "columnsum.to_excel(\"./final_data/sorted_full.xlsx\")\n",
    "\n",
    "print(\"==== completed ====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}