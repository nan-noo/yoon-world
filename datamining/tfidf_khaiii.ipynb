{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from khaiii import KhaiiiApi\n",
    "from gensim import corpora, models\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [i for i in range(2002, 2021)]\n",
    "sortedresult = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==== 2002 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  361\n",
      "# documents :  11\n",
      "==== calculating tfidf ====\n",
      "   year  컴포넌트    아동   시스템    학습   판소리    모형  프로그래밍   평가   콘텐츠  ...    위쪽  \\\n",
      "0  2002  0.87  0.72  0.68  0.62  0.58  0.57   0.57  0.5  0.49  ...  0.07   \n",
      "\n",
      "     변화    연습    어휘   아래쪽   아동감    실행   css    소리    상황  \n",
      "0  0.07  0.07  0.07  0.07  0.07  0.07  0.07  0.07  0.07  \n",
      "\n",
      "[1 rows x 362 columns]\n",
      "==== completed ====\n",
      "==== 2003 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  620\n",
      "# documents :  26\n",
      "==== calculating tfidf ====\n",
      "   year    평가    상담    환경   학습    아동  컴포넌트    수행    독서    교수  ...   거부감    충족  \\\n",
      "0  2003  1.53  1.39  1.23  1.1  0.99  0.98  0.92  0.88  0.87  ...  0.05  0.05   \n",
      "\n",
      "     친구    여건    원인    정신    허용    학급    편안    유리  \n",
      "0  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 621 columns]\n",
      "==== completed ====\n",
      "==== 2004 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  713\n",
      "# documents :  30\n",
      "==== calculating tfidf ====\n",
      "   year    상담   평가    학습    환경    교수    아동  컴포넌트   학습자    수행  ...   idf    허용  \\\n",
      "0  2004  2.17  1.6  1.54  1.21  1.07  1.02  0.99  0.95  0.93  ...  0.06  0.06   \n",
      "\n",
      "     학급    편안    친구    정신    원인    여건   분위기    결합  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 714 columns]\n",
      "==== completed ====\n",
      "==== 2005 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  792\n",
      "# documents :  34\n",
      "==== calculating tfidf ====\n",
      "   year    상담    평가    학습    환경    교수    아동  컴포넌트    통신  시스템  ...  단어가중치  \\\n",
      "0  2005  2.22  1.75  1.56  1.24  1.14  1.04  1.02  1.01  1.0  ...   0.06   \n",
      "\n",
      "     원인  역문헌빈도가중치    허용    유리    학급    정신    편안    친구   역문헌  \n",
      "0  0.06      0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 793 columns]\n",
      "==== completed ====\n",
      "==== 2006 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  817\n",
      "# documents :  37\n",
      "==== calculating tfidf ====\n",
      "   year    상담    평가    능력   학습    환경    교수  시스템    정보    통신  ...    허용    소요  \\\n",
      "0  2006  2.24  1.88  1.73  1.6  1.31  1.24  1.2  1.18  1.07  ...  0.06  0.06   \n",
      "\n",
      "    실험자   idf  단어가중치    일선    hr   교과목    편안    결합  \n",
      "0  0.06  0.06   0.06  0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 818 columns]\n",
      "==== completed ====\n",
      "==== 2007 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  1263\n",
      "# documents :  75\n",
      "==== calculating tfidf ====\n",
      "   year    학습   컴퓨터   시스템    정보    평가    상담    능력    로봇   교수  ...  markup  \\\n",
      "0  2007  2.96  2.74  2.72  2.55  2.46  2.45  2.29  2.27  2.1  ...    0.07   \n",
      "\n",
      "   processor  word    학급    허용   분위기    결합    여건    유리    편안  \n",
      "0       0.07  0.07  0.06  0.06  0.06  0.06  0.06  0.06  0.06  \n",
      "\n",
      "[1 rows x 1264 columns]\n",
      "==== completed ====\n",
      "==== 2008 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  1602\n",
      "# documents :  120\n",
      "==== calculating tfidf ====\n",
      "   year   컴퓨터  프로그래밍   시스템    정보    평가   학습    로봇    능력    교사  ...   래피드  \\\n",
      "0  2008  4.45    4.4  4.26  4.21  4.15  4.1  3.43  3.02  2.98  ...  0.06   \n",
      "\n",
      "    시너지   인용도    전장   키워드  윤리의식    범죄    방지    행위   인식도  \n",
      "0  0.06  0.06  0.06  0.06  0.05  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 1603 columns]\n",
      "==== completed ====\n",
      "==== 2009 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  1889\n",
      "# documents :  170\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍   컴퓨터    학습    정보   시스템    로봇   평가    교사    능력  ...    능률  \\\n",
      "0  2009   6.06  5.71  5.68  5.52  5.33  5.26  5.2  4.04  4.03  ...  0.06   \n",
      "\n",
      "    단행본   래피드    정체   시너지   생태계   인식도  윤리의식    범죄    방지  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 1890 columns]\n",
      "==== completed ====\n",
      "==== 2010 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  2210\n",
      "# documents :  232\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍   로봇    학습   컴퓨터    정보   시스템    평가    문제   게임  ...   단행본   생태계  \\\n",
      "0  2010   9.12  8.2  7.96  7.45  7.33  7.01  6.65  5.01  4.9  ...  0.06  0.06   \n",
      "\n",
      "    래피드  base    구안    군대   노하우    능률   인식도    방지  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.06  0.05  0.05  \n",
      "\n",
      "[1 rows x 2211 columns]\n",
      "==== completed ====\n",
      "==== 2011 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  2516\n",
      "# documents :  295\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍     로봇    학습    정보   컴퓨터  시스템    평가    교육   문제  ...    구안  \\\n",
      "0  2011  12.87  10.85  10.2  9.47  8.94  8.5  7.38  6.33  6.2  ...  0.06   \n",
      "\n",
      "     군대   노하우    능률   단행본   래피드   생태계   시너지    방지   인식도  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.05  0.05  \n",
      "\n",
      "[1 rows x 2517 columns]\n",
      "==== completed ====\n",
      "==== 2012 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  2757\n",
      "# documents :  344\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍     로봇     학습     정보   컴퓨터   시스템    평가    교육    문제  ...   시너지  \\\n",
      "0  2012  14.61  12.61  11.69  11.44  9.66  9.44  7.76  7.46  7.29  ...  0.06   \n",
      "\n",
      "    래피드    구안   과학부    능률   노하우    군대   단행본   인식도    방지  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.05  0.05  \n",
      "\n",
      "[1 rows x 2758 columns]\n",
      "==== completed ====\n",
      "==== 2013 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  2969\n",
      "# documents :  392\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍    로봇     학습     정보    컴퓨터   시스템    교육   평가    문제  ...   외국인  \\\n",
      "0  2013  16.22  15.2  13.26  12.62  11.12  10.5  8.61  8.3  8.15  ...  0.06   \n",
      "\n",
      "     전락  베타테스트    출신  twitter    남성   과학부    직장   인식도    방지  \n",
      "0  0.06   0.06  0.06     0.06  0.06  0.06  0.06  0.05  0.05  \n",
      "\n",
      "[1 rows x 2970 columns]\n",
      "==== completed ====\n",
      "==== 2014 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  3185\n",
      "# documents :  455\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍     로봇     정보    학습    컴퓨터    시스템     과학     교육    평가  ...  \\\n",
      "0  2014   19.7  18.67  15.33  15.2  13.35  11.44  10.31  10.22  9.97  ...   \n",
      "\n",
      "     직장    전락    여성    어촌    성비    총괄   책임자    방지   인식도    지휘  \n",
      "0  0.06  0.06  0.06  0.06  0.06  0.05  0.05  0.05  0.05  0.05  \n",
      "\n",
      "[1 rows x 3186 columns]\n",
      "==== completed ====\n",
      "==== 2015 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  3391\n",
      "# documents :  508\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍     로봇     학습     정보    컴퓨터    시스템     교육     과학     평가  ...  \\\n",
      "0  2015  21.93  20.46  17.27  16.82  14.65  12.43  11.32  11.12  10.87  ...   \n",
      "\n",
      "     오후   양육자  어머니인식    염려    영아    주중    주말    장르   월평균    오전  \n",
      "0  0.04  0.04   0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 3392 columns]\n",
      "==== completed ====\n",
      "==== 2016 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  3603\n",
      "# documents :  572\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍     로봇     정보     학습    컴퓨터    시스템     과학     수업     교육  ...  \\\n",
      "0  2016  24.11  21.85  19.17  18.99  16.37  13.44  12.46  12.32  12.32  ...   \n",
      "\n",
      "    양육자    염려    영아    오전    오후   월평균    장르    주말    주중    영유  \n",
      "0  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 3604 columns]\n",
      "==== completed ====\n",
      "==== 2017 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  3773\n",
      "# documents :  640\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍     로봇     정보     학습    컴퓨터    시스템    과학     과정     교육  ...  \\\n",
      "0  2017  26.29  23.59  21.42  20.87  18.07  14.65  14.1  13.79  13.76  ...   \n",
      "\n",
      "     주중    주말    장르    가계    소득   양육자    오후  어머니인식    염려    영아  \n",
      "0  0.04  0.04  0.04  0.04  0.04  0.04  0.04   0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 3774 columns]\n",
      "==== completed ====\n",
      "==== 2018 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  3942\n",
      "# documents :  709\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍     로봇     정보     학습    컴퓨터     sw    시스템     교사     과정  ...  \\\n",
      "0  2018   27.8  26.15  23.12  22.94  19.28  17.76  15.67  15.55  15.29  ...   \n",
      "\n",
      "     오전    오후  어머니인식   양육자    소득    가계    장르    주말    주중    영유  \n",
      "0  0.04  0.04   0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 3943 columns]\n",
      "==== completed ====\n",
      "==== 2019 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  4099\n",
      "# documents :  775\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍     로봇     정보     학습     sw    컴퓨터    컴퓨팅     교사    시스템  ...  \\\n",
      "0  2019  29.27  27.54  24.85  24.81  20.73  20.66  17.66  17.35  16.75  ...   \n",
      "\n",
      "     주말  어머니인식    장르    오후    오전    영유    영아    가계   양육자    소득  \n",
      "0  0.04   0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 4100 columns]\n",
      "==== completed ====\n",
      "==== 2020 ====\n",
      "========= tokenization completed =========\n",
      "# words in total :  4217\n",
      "# documents :  812\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍    로봇     정보     학습     sw    컴퓨터   컴퓨팅    교사    시스템  ...  \\\n",
      "0  2020  30.26  28.9  25.97  25.59  22.81  21.14  19.4  18.0  17.24  ...   \n",
      "\n",
      "     소득   양육자  어머니인식    염려    영아    영유    오전    주중    주말    오후  \n",
      "0  0.04  0.04   0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04  \n",
      "\n",
      "[1 rows x 4218 columns]\n",
      "==== completed ====\n"
     ]
    }
   ],
   "source": [
    "for i in range(19):\n",
    "    print(\"==== \"+str(year[i])+\" ====\")\n",
    "    data = pd.read_csv(\"./modi_data/kor_\"+str(year[i])+\".csv\")\n",
    "    #data = data.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "    dfWordList = pd.read_excel(\"./khaiii_word_cor.xlsx\")\n",
    "    dfWordList2 = pd.read_excel(\"./khaiii_word_cor_etc.xlsx\")\n",
    "    #print(dfWordList2)\n",
    "\n",
    "    dfWordDel = dfWordList[dfWordList[\"수정\"] == \"삭제\"]\n",
    "    dfWordMod = dfWordList[dfWordList[\"수정\"] != \"삭제\"]\n",
    "    dfWordDiv = dfWordList2\n",
    "    #print(dfWordMod)\n",
    "\n",
    "    seriesDelete = dfWordDel[\"기존\"]\n",
    "    stopword = []\n",
    "    for word in seriesDelete.values:\n",
    "        stopword.append(word)\n",
    "    #print(stopword)\n",
    "\n",
    "    seriesModify = dfWordMod[\"기존\"]\n",
    "    modiword = []\n",
    "    for word in seriesModify.values:\n",
    "        modiword.append(word)\n",
    "    #print(len(modiword))\n",
    "\n",
    "    seriesModify2 = dfWordMod[\"수정\"]\n",
    "    modiword2 = []\n",
    "    for word in seriesModify2.values:\n",
    "        modiword2.append(word)\n",
    "    #print(len(modiword2))\n",
    "\n",
    "    seriesDivide = dfWordDiv[\"기존\"]\n",
    "    divword = []\n",
    "    for word in seriesDivide.values:\n",
    "        divword.append(word)\n",
    "    #print(divword)\n",
    "    #print(len(divword))\n",
    "\n",
    "    seriesDivide2 = dfWordDiv[\"수정\"]\n",
    "    divword2 = []\n",
    "    for words in seriesDivide2.values:\n",
    "        divword2.append(words.split(', '))\n",
    "    #print(divword2)\n",
    "    #print(len(divword2))\n",
    "\n",
    "\n",
    "    api = KhaiiiApi()\n",
    "    def khaiiiTokenizer(raw, stopword=stopword, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL']): # 일반명사 고유명사 의존명사 대명사 수사 외국어\n",
    "        list = []\n",
    "        \n",
    "        for word in api.analyze(raw): #raw data\n",
    "            #print(word)\n",
    "            \n",
    "            for morph in word.morphs:\n",
    "                #print(morph.lex)\n",
    "                if len(morph.lex) > 1 and morph.tag in pos and morph.lex not in stopword: \n",
    "                    if morph.tag == 'SL':\n",
    "                        morph.lex = morph.lex.lower()\n",
    "                    if morph.lex in divword:\n",
    "                        morph.lex = divword2[divword.index(morph.lex)]\n",
    "                        list.extend(morph.lex)\n",
    "                    elif morph.lex in modiword:\n",
    "                        morph.lex = modiword2[modiword.index(morph.lex)]\n",
    "                        list.append(morph.lex)\n",
    "                    else: list.append(morph.lex)\n",
    "                    \n",
    "        return list\n",
    "\n",
    "    tokenized = data[\"kor_full\"].apply(lambda row: khaiiiTokenizer(row))\n",
    "    #print(tokenized)\n",
    "    #tokenized.to_excel(\"./finaldata/0911token_full.xls\") ##############\n",
    "    print(\"========= tokenization completed =========\")\n",
    "\n",
    "    id2word = corpora.Dictionary(tokenized)\n",
    "    corpus=[id2word.doc2bow(text) for text in tokenized]\n",
    "    print(\"# words in total : \", len(id2word))\n",
    "    print(\"# documents : \", len(corpus))\n",
    "\n",
    "    #tfidf\n",
    "    print(\"==== calculating tfidf ====\")\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "    #tfidf per doc\n",
    "    tfidflist = []\n",
    "    for doc in tfidf[corpus]:\n",
    "        inner_list = [0]*len(id2word) \n",
    "        for id, freq in doc:\n",
    "            inner_list[id] = np.around(freq, decimals=2) #put tfidf value in the place matching its index\n",
    "        tfidflist.append(inner_list)\n",
    "    #print(len(tfidflist))\n",
    "\n",
    "    tfidf_df = pd.DataFrame(tfidflist)\n",
    "    tfidf_df.columns = [id2word[i] for i in range(len(id2word))] #set columns' names as words\n",
    "    #print(tfidf_df)\n",
    "\n",
    "    total_df = pd.concat([data[[\"year\", \"no\"]], tfidf_df], axis=1)\n",
    "    #print(total_df)\n",
    "    total_df.to_excel(\"./final_data/tfidf\"+str(year[i])+\".xlsx\") \n",
    "\n",
    "    #sum of tfidf for each word\n",
    "    columnsum = pd.DataFrame(total_df.sum(axis=0)).T\n",
    "    columnsum = columnsum.drop(['no'], axis=1)\n",
    "    columnsum['year'] = year[i]\n",
    "    #print(columnsum)\n",
    "    columnsum.to_excel(\"./final_data/sum\"+str(year[i])+\".xlsx\")\n",
    "\n",
    "    #sort tfidf value in descending order\n",
    "    columnsum = columnsum.sort_values(by=0, axis=1, ascending=False)\n",
    "    print(columnsum)\n",
    "    columnsum.to_excel(\"./final_data/sorted\"+str(year[i])+\".xlsx\")\n",
    "\n",
    "    print(\"==== completed ====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========= tokenization completed =========\n",
      "# words in total :  4217\n",
      "# documents :  812\n",
      "==== calculating tfidf ====\n",
      "   year  프로그래밍    로봇     정보     학습     sw    컴퓨터   컴퓨팅    교사    시스템  ...  \\\n",
      "0  2020  30.26  28.9  25.97  25.59  22.81  21.14  19.4  18.0  17.24  ...   \n",
      "\n",
      "    양육자    오후    주말    오전    영유    영아    염려    주중  어머니인식    장르  \n",
      "0  0.04  0.04  0.04  0.04  0.04  0.04  0.04  0.04   0.04  0.04  \n",
      "\n",
      "[1 rows x 4218 columns]\n",
      "==== completed ====\n"
     ]
    }
   ],
   "source": [
    "# tfidf for full data\n",
    "\n",
    "data = pd.read_csv(\"./modi_data/kor_full.csv\")\n",
    "#data = data.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "dfWordList = pd.read_excel(\"./khaiii_word_cor.xlsx\")\n",
    "dfWordList2 = pd.read_excel(\"./khaiii_word_cor_etc.xlsx\")\n",
    "#print(dfWordList2)\n",
    "\n",
    "dfWordDel = dfWordList[dfWordList[\"수정\"] == \"삭제\"]\n",
    "dfWordMod = dfWordList[dfWordList[\"수정\"] != \"삭제\"]\n",
    "dfWordDiv = dfWordList2\n",
    "#print(dfWordMod)\n",
    "\n",
    "seriesDelete = dfWordDel[\"기존\"]\n",
    "stopword = []\n",
    "for word in seriesDelete.values:\n",
    "    stopword.append(word)\n",
    "#print(stopword)\n",
    "\n",
    "seriesModify = dfWordMod[\"기존\"]\n",
    "modiword = []\n",
    "for word in seriesModify.values:\n",
    "    modiword.append(word)\n",
    "#print(len(modiword))\n",
    "\n",
    "seriesModify2 = dfWordMod[\"수정\"]\n",
    "modiword2 = []\n",
    "for word in seriesModify2.values:\n",
    "    modiword2.append(word)\n",
    "#print(len(modiword2))\n",
    "\n",
    "seriesDivide = dfWordDiv[\"기존\"]\n",
    "divword = []\n",
    "for word in seriesDivide.values:\n",
    "    divword.append(word)\n",
    "#print(divword)\n",
    "#print(len(divword))\n",
    "\n",
    "seriesDivide2 = dfWordDiv[\"수정\"]\n",
    "divword2 = []\n",
    "for words in seriesDivide2.values:\n",
    "    divword2.append(words.split(', '))\n",
    "#print(divword2)\n",
    "#print(len(divword2))\n",
    "\n",
    "\n",
    "api = KhaiiiApi()\n",
    "def khaiiiTokenizer(raw, stopword=stopword, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL']): # 일반명사 고유명사 의존명사 대명사 수사 외국어\n",
    "    list = []\n",
    "    \n",
    "    for word in api.analyze(raw): #raw data\n",
    "        #print(word)\n",
    "        \n",
    "        for morph in word.morphs:\n",
    "            #print(morph.lex)\n",
    "            if len(morph.lex) > 1 and morph.tag in pos and morph.lex not in stopword: \n",
    "                if morph.tag == 'SL':\n",
    "                    morph.lex = morph.lex.lower()\n",
    "                if morph.lex in divword:\n",
    "                    morph.lex = divword2[divword.index(morph.lex)]\n",
    "                    list.extend(morph.lex)\n",
    "                elif morph.lex in modiword:\n",
    "                    morph.lex = modiword2[modiword.index(morph.lex)]\n",
    "                    list.append(morph.lex)\n",
    "                else: list.append(morph.lex)\n",
    "                \n",
    "    return list\n",
    "\n",
    "tokenized = data[\"kor_full\"].apply(lambda row: khaiiiTokenizer(row))\n",
    "#print(tokenized)\n",
    "#tokenized.to_excel(\"./finaldata/0911token_full.xls\") ##############\n",
    "print(\"========= tokenization completed =========\")\n",
    "\n",
    "id2word = corpora.Dictionary(tokenized)\n",
    "corpus=[id2word.doc2bow(text) for text in tokenized]\n",
    "print(\"# words in total : \", len(id2word))\n",
    "print(\"# documents : \", len(corpus))\n",
    "\n",
    "#tfidf\n",
    "print(\"==== calculating tfidf ====\")\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "#tfidf per doc\n",
    "tfidflist = []\n",
    "for doc in tfidf[corpus]:\n",
    "    inner_list = [0]*len(id2word) \n",
    "    for id, freq in doc:\n",
    "        inner_list[id] = np.around(freq, decimals=2) #put tfidf value in the place matching its index\n",
    "    tfidflist.append(inner_list)\n",
    "#print(len(tfidflist))\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidflist)\n",
    "tfidf_df.columns = [id2word[i] for i in range(len(id2word))] #set columns' names as words\n",
    "#print(tfidf_df)\n",
    "\n",
    "total_df = pd.concat([data[[\"year\", \"no\"]], tfidf_df], axis=1)\n",
    "#print(total_df)\n",
    "total_df.to_excel(\"./final_data/tfidf_full.xlsx\") \n",
    "\n",
    "#sum of tfidf for each word\n",
    "columnsum = pd.DataFrame(total_df.sum(axis=0)).T\n",
    "columnsum = columnsum.drop(['no'], axis=1)\n",
    "columnsum['year'] = year[i]\n",
    "#print(columnsum)\n",
    "columnsum.to_excel(\"./final_data/sum_full.xlsx\")\n",
    "\n",
    "#sort tfidf value in descending order\n",
    "columnsum = columnsum.sort_values(by=0, axis=1, ascending=False)\n",
    "print(columnsum)\n",
    "columnsum.to_excel(\"./final_data/sorted_full.xlsx\")\n",
    "\n",
    "print(\"==== completed ====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}