{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/uni613/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from khaiii import KhaiiiApi\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "import numpy as np\n",
    "import logging\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/uni613/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    no  year                                   title  \\\n",
       "0  137  2002             탐색 알고리즘 교육을 위한 S/W 컴포넌트의 개발   \n",
       "1  147  2002  프로젝트 학습을 기반으로 하는 ICT 활용 수업 모형의 개발 및 적용   \n",
       "2  148  2002         분산 컴퓨팅 환경에서의 웹 교육 컴포넌트 개발과정 모델링   \n",
       "3  149  2002  효과적인 아동용 WBI를 위한 한글 타이포그래피의 가해성 분석과 활용   \n",
       "4  150  2002   교수 · 학습 디지털 컨텐트 통합메타데이터 및 개체-관계 모델 설계   \n",
       "\n",
       "                                            kor_full  \n",
       "0  탐색 알고리즘 교육을 위한 S/W 컴포넌트의 개발 탐색알고리즘교육, 컴퓨터프로그래밍...  \n",
       "1  프로젝트 학습을 기반으로 하는 ICT 활용 수업 모형의 개발 및 적용 ICT 활용교...  \n",
       "2  분산 컴퓨팅 환경에서의 웹 교육 컴포넌트 개발과정 모델링 웹기반 교육, 컴포넌트 개...  \n",
       "3  효과적인 아동용 WBI를 위한 한글 타이포그래피의 가해성 분석과 활용 타이포 그래피...  \n",
       "4  교수 · 학습 디지털 컨텐트 통합메타데이터 및 개체-관계 모델 설계 교수.학습, 컨...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>no</th>\n      <th>year</th>\n      <th>title</th>\n      <th>kor_full</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>137</td>\n      <td>2002</td>\n      <td>탐색 알고리즘 교육을 위한 S/W 컴포넌트의 개발</td>\n      <td>탐색 알고리즘 교육을 위한 S/W 컴포넌트의 개발 탐색알고리즘교육, 컴퓨터프로그래밍...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>147</td>\n      <td>2002</td>\n      <td>프로젝트 학습을 기반으로 하는 ICT 활용 수업 모형의 개발 및 적용</td>\n      <td>프로젝트 학습을 기반으로 하는 ICT 활용 수업 모형의 개발 및 적용 ICT 활용교...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>148</td>\n      <td>2002</td>\n      <td>분산 컴퓨팅 환경에서의 웹 교육 컴포넌트 개발과정 모델링</td>\n      <td>분산 컴퓨팅 환경에서의 웹 교육 컴포넌트 개발과정 모델링 웹기반 교육, 컴포넌트 개...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>149</td>\n      <td>2002</td>\n      <td>효과적인 아동용 WBI를 위한 한글 타이포그래피의 가해성 분석과 활용</td>\n      <td>효과적인 아동용 WBI를 위한 한글 타이포그래피의 가해성 분석과 활용 타이포 그래피...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>150</td>\n      <td>2002</td>\n      <td>교수 · 학습 디지털 컨텐트 통합메타데이터 및 개체-관계 모델 설계</td>\n      <td>교수 · 학습 디지털 컨텐트 통합메타데이터 및 개체-관계 모델 설계 교수.학습, 컨...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "data = pd.read_csv(\"./modi_data/kor_full.csv\") ############\n",
    "#data = data.drop(['Unnamed: 0'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       no  year                                              title  \\\n",
      "0     137  2002                        탐색 알고리즘 교육을 위한 S/W 컴포넌트의 개발   \n",
      "1     147  2002             프로젝트 학습을 기반으로 하는 ICT 활용 수업 모형의 개발 및 적용   \n",
      "2     148  2002                    분산 컴퓨팅 환경에서의 웹 교육 컴포넌트 개발과정 모델링   \n",
      "3     149  2002             효과적인 아동용 WBI를 위한 한글 타이포그래피의 가해성 분석과 활용   \n",
      "4     150  2002              교수 · 학습 디지털 컨텐트 통합메타데이터 및 개체-관계 모델 설계   \n",
      "..    ...   ...                                                ...   \n",
      "807  1121  2020       R 매핑을 이용한 인공지능의 교육적 활용 탐색 - 국외 문헌 분석을 중심으로 -   \n",
      "808  1122  2020                 중학교 정보교과에서 짝 프로그래밍이 4Cs 향상에 미치는 영향   \n",
      "809  1123  2020                         자동 분류 기술을 활용한 온라인 강의 평가 방법   \n",
      "810  1124  2020               인공지능교육 역량 강화를 위한 교원 연수 프로그램과 교사 요구분석   \n",
      "811  1125  2020  초·중등 현직 교원의 스크래치 활용 교수자료 개발에 대한 경험 분석 : ASSURE...   \n",
      "\n",
      "                                              kor_full  \n",
      "0    탐색 알고리즘 교육을 위한 S/W 컴포넌트의 개발 탐색알고리즘교육, 컴퓨터프로그래밍...  \n",
      "1    프로젝트 학습을 기반으로 하는 ICT 활용 수업 모형의 개발 및 적용 ICT 활용교...  \n",
      "2    분산 컴퓨팅 환경에서의 웹 교육 컴포넌트 개발과정 모델링 웹기반 교육, 컴포넌트 개...  \n",
      "3    효과적인 아동용 WBI를 위한 한글 타이포그래피의 가해성 분석과 활용 타이포 그래피...  \n",
      "4    교수 · 학습 디지털 컨텐트 통합메타데이터 및 개체-관계 모델 설계 교수.학습, 컨...  \n",
      "..                                                 ...  \n",
      "807  R 매핑을 이용한 인공지능의 교육적 활용 탐색 - 국외 문헌 분석을 중심으로 - 인...  \n",
      "808  중학교 정보교과에서 짝 프로그래밍이 4Cs 향상에 미치는 영향 짝 프로그래밍, 4C...  \n",
      "809  자동 분류 기술을 활용한 온라인 강의 평가 방법 빅 데이터 분석, 온라인 강의 평가...  \n",
      "810  인공지능교육 역량 강화를 위한 교원 연수 프로그램과 교사 요구분석 인공지능교육, 교...  \n",
      "811  초·중등 현직 교원의 스크래치 활용 교수자료 개발에 대한 경험 분석 : ASSURE...  \n",
      "\n",
      "[812 rows x 4 columns]\n",
      "/Users/uni613/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./modi_data/kor_full.csv\") ############\n",
    "#data = data.drop(data.index[50:]) ###################### decrease size\n",
    "#data = data.drop(['Unnamed: 0'], axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/uni613/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "dfWordList = pd.read_excel(\"./khaiii_word_cor.xlsx\")\n",
    "dfWordList2 = pd.read_excel(\"./khaiii_word_cor_etc.xlsx\")\n",
    "#print(dfWordList2)\n",
    "\n",
    "dfWordDel = dfWordList[dfWordList[\"수정\"] == \"삭제\"]\n",
    "dfWordMod = dfWordList[dfWordList[\"수정\"] != \"삭제\"]\n",
    "dfWordDiv = dfWordList2\n",
    "#print(dfWordMod)\n",
    "\n",
    "seriesDelete = dfWordDel[\"기존\"]\n",
    "stopword = []\n",
    "for word in seriesDelete.values:\n",
    "    stopword.append(word)\n",
    "#print(stopword)\n",
    "\n",
    "seriesModify = dfWordMod[\"기존\"]\n",
    "modiword = []\n",
    "for word in seriesModify.values:\n",
    "    modiword.append(word)\n",
    "#print(len(modiword))\n",
    "\n",
    "seriesModify2 = dfWordMod[\"수정\"]\n",
    "modiword2 = []\n",
    "for word in seriesModify2.values:\n",
    "    modiword2.append(word)\n",
    "#print(len(modiword2))\n",
    "\n",
    "seriesDivide = dfWordDiv[\"기존\"]\n",
    "divword = []\n",
    "for word in seriesDivide.values:\n",
    "    divword.append(word)\n",
    "#print(divword)\n",
    "#print(len(divword))\n",
    "\n",
    "seriesDivide2 = dfWordDiv[\"수정\"]\n",
    "divword2 = []\n",
    "for words in seriesDivide2.values:\n",
    "    divword2.append(words.split(', '))\n",
    "#print(divword2)\n",
    "#print(len(divword2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/uni613/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "api = KhaiiiApi()\n",
    "def khaiiiTokenizer(raw, stopword=stopword, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL']): # 일반명사 고유명사 의존명사 대명사 수사 외국어\n",
    "    list = []\n",
    "    \n",
    "    for word in api.analyze(raw): #raw data\n",
    "        #print(word)\n",
    "        \n",
    "        for morph in word.morphs:\n",
    "            #print(morph.lex)\n",
    "            if len(morph.lex) > 1 and morph.tag in pos and morph.lex not in stopword: \n",
    "                if morph.tag == 'SL':\n",
    "                    morph.lex = morph.lex.lower()\n",
    "                if morph.lex in divword:\n",
    "                    morph.lex = divword2[divword.index(morph.lex)]\n",
    "                    list.extend(morph.lex)\n",
    "                elif morph.lex in modiword:\n",
    "                    morph.lex = modiword2[modiword.index(morph.lex)]\n",
    "                    list.append(morph.lex)\n",
    "                else: list.append(morph.lex)\n",
    "                \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/uni613/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "========= tokenization completed =========\n"
     ]
    }
   ],
   "source": [
    "tokenized = data[\"kor_full\"].apply(lambda row: khaiiiTokenizer(row))\n",
    "#print(tokenized)\n",
    "tokenized.to_excel(\"./final_data/1210token_khaiii_full.xls\") ##############\n",
    "print(\"========= tokenization completed =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/uni613/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "# words in total :  4217\n",
      "# documents :  812\n"
     ]
    }
   ],
   "source": [
    "#lda\n",
    "id2word = gensim.corpora.Dictionary(tokenized)\n",
    "\n",
    "wordlist = []\n",
    "for i in range(len(id2word)):\n",
    "    #print(id2word[i])\n",
    "    wordlist.append(id2word[i])\n",
    "#print(wordlist)\n",
    "seriesWordlist = pd.Series(wordlist)\n",
    "seriesWordlist.to_excel(\"./final_data/1210wordlist_khaiii_full.xls\") #################\n",
    "\n",
    "corpus=[id2word.doc2bow(text) for text in tokenized]\n",
    "#print(\"id2word for each document : \", corpus)\n",
    "print(\"# words in total : \", len(id2word))\n",
    "print(\"# documents : \", len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/uni613/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=1):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    perplexity_values = []\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        print(num_topics)\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=num_topics,\n",
    "                                                random_state=100,\n",
    "                                                update_every=1,\n",
    "                                                iterations=1000,\n",
    "                                                chunksize=100,\n",
    "                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "                                                eta='auto',\n",
    "                                                per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        perplexitymodel = model.log_perplexity(corpus)\n",
    "        perplexity_values.append(perplexitymodel)\n",
    "        coherencemodel = CoherenceModel(model=model,\n",
    "                                        texts=texts,\n",
    "                                        dictionary=dictionary,\n",
    "                                        coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, perplexity_values, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/uni613/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "2\n",
      "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
      "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
      "3\n",
      "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
      "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
      "4\n",
      "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "model_list, perplexity_values, coherence_values = compute_coherence_values(dictionary=id2word,\n",
    "                                                        corpus=corpus,\n",
    "                                                        texts=tokenized,\n",
    "                                                        start=2,\n",
    "                                                        limit=31, #####\n",
    "                                                        step=1)\n",
    "#print(\"time : \", ( time.time() - start )/60, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=31 ######\n",
    "start=2\n",
    "step=1\n",
    "x = range(start, limit, step)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(10, 10))\n",
    "\n",
    "ax[0].plot(x, perplexity_values, marker='o')\n",
    "ax[0].set_xlabel(\"Number of Topics\")\n",
    "ax[0].set_ylabel(\"Perplexity\")\n",
    "ax[0].legend((\"perplexity\"), loc='best')\n",
    "\n",
    "ax[1].plot(x, coherence_values, marker='o')\n",
    "ax[1].set_xlabel(\"Number of Topics\")\n",
    "ax[1].set_ylabel(\"Coherence score\")\n",
    "ax[1].legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, pv in zip(x, perplexity_values):\n",
    "  print(\"Num Topics =\", m, \" has Perplexity Value of\", round(pv, 4))\n",
    "\n",
    "for m, cv in zip(x, coherence_values):\n",
    "  print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = int(input(\"set the number of topics \"))\n",
    "optimal_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=a,\n",
    "                                                random_state=100,\n",
    "                                                update_every=1,\n",
    "                                                iterations=1000,\n",
    "                                                chunksize=100,\n",
    "                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "                                                eta='auto',\n",
    "                                                per_word_topics=True)\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = input(\"set the title of html file \")\n",
    "vis = pyLDAvis.gensim.prepare(optimal_model, corpus, id2word)\n",
    "pyLDAvis.save_html(vis, title+\".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# topic proportion\n",
    "# num of optimal topics = 12\n",
    "\n",
    "proportion = []\n",
    "for i, row_list in enumerate(optimal_model[corpus]):\n",
    "    #print(\"document number : \", i)\n",
    "    row = row_list[0]\n",
    "    #print(row)\n",
    "    proportion.append(row)\n",
    "print(pd.DataFrame(proportion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proportion = []\n",
    "for i, row_list in enumerate(optimal_model[corpus]):\n",
    "    #print(\"document number : \", i)\n",
    "    row = row_list[0]\n",
    "    #print(row)\n",
    "    inner_proportion = [\"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\"] # numtopics 12\n",
    "    for j, (topic_num, prop) in enumerate(row):\n",
    "        for k in range(12): # numtopics 12\n",
    "            if topic_num == k:\n",
    "                inner_proportion[k] = prop\n",
    "    proportion.append(inner_proportion)\n",
    "    #print(inner_proportion)\n",
    "#print(proportion)\n",
    "\n",
    "#topic_proportions = pd.DataFrame(data[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportions = pd.concat([data[\"title\"], pd.DataFrame(proportion)], axis=1)\n",
    "topic_proportions.columns = [\"Title\", \"T0\", \"T1\", \"T2\", \"T3\", \"T4\", \"T5\", \"T6\", \"T7\", \"T8\", \"T9\", \"T10\", \"T11\"] #num topics = 12\n",
    "print(topic_proportions)\n",
    "topic_proportions.to_excel(\"./final_data/1210_topic_proportions_total.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}