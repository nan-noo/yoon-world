{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from khaiii import KhaiiiApi\n",
    "import gensim\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   no  year                     title                      kor_full\n",
       "0   1  1997         멀티미디어 원격교육에 관한 연구         멀티미디어 원격교육에 관한 연구    \n",
       "1   2  1997  교육용 하이퍼미디어 자료 편집기에 관한 연구  교육용 하이퍼미디어 자료 편집기에 관한 연구    \n",
       "2   3  1997     인터넷 기반의 코스웨어의 설계 및 구현     인터넷 기반의 코스웨어의 설계 및 구현    \n",
       "3   4  1997     Web에서의 협력 환경 구축 방안 연구     Web에서의 협력 환경 구축 방안 연구    \n",
       "4   5  1997        열린교육에서의 개별화수업과 CAI        열린교육에서의 개별화수업과 CAI    "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>no</th>\n      <th>year</th>\n      <th>title</th>\n      <th>kor_full</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1997</td>\n      <td>멀티미디어 원격교육에 관한 연구</td>\n      <td>멀티미디어 원격교육에 관한 연구</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1997</td>\n      <td>교육용 하이퍼미디어 자료 편집기에 관한 연구</td>\n      <td>교육용 하이퍼미디어 자료 편집기에 관한 연구</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1997</td>\n      <td>인터넷 기반의 코스웨어의 설계 및 구현</td>\n      <td>인터넷 기반의 코스웨어의 설계 및 구현</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1997</td>\n      <td>Web에서의 협력 환경 구축 방안 연구</td>\n      <td>Web에서의 협력 환경 구축 방안 연구</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1997</td>\n      <td>열린교육에서의 개별화수업과 CAI</td>\n      <td>열린교육에서의 개별화수업과 CAI</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv(\"./modi_data/kor_full.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWordList = pd.read_excel(\"./khaiii_word_cor.xlsx\")\n",
    "dfWordList2 = pd.read_excel(\"./khaiii_word_cor_etc.xlsx\")\n",
    "#print(dfWordList2)\n",
    "\n",
    "dfWordDel = dfWordList[dfWordList[\"수정\"] == \"삭제\"]\n",
    "dfWordMod = dfWordList[dfWordList[\"수정\"] != \"삭제\"]\n",
    "dfWordDiv = dfWordList2\n",
    "#print(dfWordMod)\n",
    "\n",
    "seriesDelete = dfWordDel[\"기존\"]\n",
    "stopword = []\n",
    "for word in seriesDelete.values:\n",
    "    stopword.append(word)\n",
    "#print(stopword)\n",
    "\n",
    "seriesModify = dfWordMod[\"기존\"]\n",
    "modiword = []\n",
    "for word in seriesModify.values:\n",
    "    modiword.append(word)\n",
    "#print(len(modiword))\n",
    "\n",
    "seriesModify2 = dfWordMod[\"수정\"]\n",
    "modiword2 = []\n",
    "for word in seriesModify2.values:\n",
    "    modiword2.append(word)\n",
    "#print(len(modiword2))\n",
    "\n",
    "seriesDivide = dfWordDiv[\"기존\"]\n",
    "divword = []\n",
    "for word in seriesDivide.values:\n",
    "    divword.append(word)\n",
    "#print(divword)\n",
    "#print(len(divword))\n",
    "\n",
    "seriesDivide2 = dfWordDiv[\"수정\"]\n",
    "divword2 = []\n",
    "for words in seriesDivide2.values:\n",
    "    divword2.append(words.split(', '))\n",
    "#print(divword2)\n",
    "#print(len(divword2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KhaiiiApi()\n",
    "def khaiiiTokenizer(raw, stopword=stopword, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL'], minLen=1): # 일반명사 고유명사 의존명사 대명사 수사 외국어\n",
    "    list = []\n",
    "    skip = 0\n",
    "\n",
    "    for word in api.analyze(raw): #raw data\n",
    "        #print(word)\n",
    "        \n",
    "        for i, morph in enumerate(word.morphs):\n",
    "            #print(morph.lex)\n",
    "            if skip == 1: \n",
    "                #print(morph.lex) # '지능'\n",
    "                skip = 0\n",
    "                continue\n",
    "\n",
    "            if morph.lex == '인공' and i+1 < len(word.morphs) and word.morphs[i+1].lex == \"지능\":\n",
    "                #print(morph.lex + word.morphs[i+1].lex) # 인공지능\n",
    "                list.append(morph.lex + word.morphs[i+1].lex)\n",
    "                skip = 1\n",
    "                continue\n",
    "\n",
    "            if len(morph.lex) > minLen and morph.tag in pos and morph.lex not in stopword: \n",
    "                if morph.tag == 'SL':\n",
    "                    morph.lex = morph.lex.lower()\n",
    "                if morph.lex in divword:\n",
    "                    morph.lex = divword2[divword.index(morph.lex)]\n",
    "                    list.extend(morph.lex)\n",
    "                elif morph.lex in modiword:\n",
    "                    morph.lex = modiword2[modiword.index(morph.lex)]\n",
    "                    list.append(morph.lex)\n",
    "                else: list.append(morph.lex)\n",
    "                \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                                     [멀티미디어, 원격, 교육, 연구]\n1                               [교육, 하이퍼미디어, 자료, 편집기, 연구]\n2                                     [인터넷, 코스웨어, 설계, 구현]\n3                               [web, 협력, 환경, 구축, 방안, 연구]\n4                                       [교육, 개별, 수업, cai]\n                              ...                        \n1144    [개정, 교과서, 소프트웨어, 교육, 단원, 탐구, 비교, 분석, 교육, 과정, 교...\n1145    [이러닝, 콘텐츠, 사용자, 경험, ux, 평가, 이러닝, 대리, 상호, 작용, 사...\n1146    [초등, 데이터, 리터러시, 함양, ai, 데이터, 과학, 교육, 프로그램, 개발,...\n1147    [초등, 예비, 교사, 소프트웨어, 교육, 온라인, 교육, 효과, 분석, 소프트웨어...\n1148    [초등, 교과서, 소프트웨어교육, 영역, 컴퓨팅, 사고력, 요소, 분석, 소프트웨어...\nName: kor_full, Length: 1149, dtype: object\n========= tokenization completed =========\n"
     ]
    }
   ],
   "source": [
    "tokenized = data[\"kor_full\"].apply(lambda row: khaiiiTokenizer(row))\n",
    "print(tokenized)\n",
    "#tokenized.to_csv(\"./modi_data/token_khaiii.csv\")\n",
    "print(\"========= tokenization completed =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# words in total :  5086\n# documents :  1149\n"
     ]
    }
   ],
   "source": [
    "#lda\n",
    "id2word = gensim.corpora.Dictionary(tokenized)\n",
    "\n",
    "corpus=[id2word.doc2bow(text) for text in tokenized]\n",
    "#print(\"id2word for each document : \", corpus)\n",
    "print(\"# words in total : \", len(id2word))\n",
    "print(\"# documents : \", len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0,\n  '0.072*\"수업\" + 0.052*\"활용\" + 0.050*\"문제\" + 0.041*\"학생\" + 0.041*\"대상\" + 0.040*\"효과\" '\n  '+ 0.036*\"적용\" + 0.029*\"연구\" + 0.027*\"모형\" + 0.026*\"중심\"'),\n (1,\n  '0.120*\"인공지능\" + 0.094*\"ai\" + 0.078*\"데이터\" + 0.078*\"창의\" + 0.071*\"알고리즘\" + '\n  '0.040*\"융합\" + 0.037*\"프로그램\" + 0.028*\"모델\" + 0.026*\"탐색\" + 0.020*\"분야\"'),\n (2,\n  '0.138*\"측정\" + 0.072*\"정도\" + 0.067*\"it\" + 0.036*\"문서\" + 0.030*\"타당도\" + '\n  '0.030*\"산출\" + 0.021*\"범주\" + 0.015*\"xml\" + 0.013*\"상관관계\" + 0.011*\"밀접\"'),\n (3,\n  '0.318*\"평가\" + 0.078*\"유형\" + 0.060*\"수행\" + 0.042*\"플랫폼\" + 0.033*\"단원\" + '\n  '0.029*\"이러닝\" + 0.027*\"절차\" + 0.021*\"발표\" + 0.021*\"관찰\" + 0.017*\"iptv\"'),\n (4,\n  '0.117*\"로봇\" + 0.081*\"영향\" + 0.047*\"분석\" + 0.040*\"교과서\" + 0.033*\"유의미\" + '\n  '0.029*\"빅데이터\" + 0.028*\"긍정\" + 0.027*\"사용\" + 0.026*\"연수\" + 0.025*\"통계\"'),\n (5,\n  '0.106*\"컴퓨팅\" + 0.105*\"프로그래밍\" + 0.087*\"사고력\" + 0.046*\"프로그램\" + 0.043*\"교육\" + '\n  '0.039*\"초등\" + 0.024*\"사고\" + 0.023*\"게임\" + 0.022*\"소프트웨어교육\" + 0.021*\"개발\"'),\n (6,\n  '0.060*\"시스템\" + 0.046*\"온라인\" + 0.041*\"집단\" + 0.032*\"확인\" + 0.029*\"기준\" + '\n  '0.028*\"이용\" + 0.025*\"전문가\" + 0.024*\"학생\" + 0.020*\"산업\" + 0.018*\"지원\"'),\n (7,\n  '0.065*\"디지털\" + 0.062*\"스크래치\" + 0.059*\"환경\" + 0.032*\"상호\" + 0.027*\"작용\" + '\n  '0.022*\"자동\" + 0.021*\"구체\" + 0.021*\"정책\" + 0.020*\"설계\" + 0.019*\"사용자\"'),\n (8,\n  '0.173*\"검사\" + 0.060*\"지능\" + 0.048*\"문항\" + 0.043*\"진로\" + 0.039*\"선행\" + 0.037*\"진단\" '\n  '+ 0.033*\"보조\" + 0.024*\"직업\" + 0.023*\"오류\" + 0.020*\"다중\"'),\n (9,\n  '0.169*\"학습\" + 0.043*\"학습자\" + 0.039*\"교수\" + 0.034*\"활동\" + 0.020*\"연구\" + '\n  '0.018*\"요소\" + 0.017*\"단계\" + 0.016*\"개발\" + 0.014*\"이해\" + 0.014*\"방법\"'),\n (10,\n  '0.156*\"교육\" + 0.040*\"연구\" + 0.037*\"분석\" + 0.035*\"초등\" + 0.032*\"정보\" + 0.028*\"과정\" '\n  '+ 0.028*\"sw\" + 0.027*\"교사\" + 0.020*\"컴퓨터\" + 0.018*\"소프트웨어\"'),\n (11,\n  '0.089*\"개정\" + 0.061*\"지속\" + 0.049*\"원격\" + 0.048*\"국내\" + 0.047*\"발문\" + 0.036*\"대응\" '\n  '+ 0.032*\"동향\" + 0.027*\"우수\" + 0.026*\"어플리케이션\" + 0.025*\"저작\"'),\n (12,\n  '0.122*\"ict\" + 0.076*\"활용\" + 0.074*\"능력\" + 0.061*\"리터러시\" + 0.047*\"스마트폰\" + '\n  '0.031*\"강의\" + 0.028*\"학기\" + 0.022*\"학생\" + 0.020*\"sns\" + 0.019*\"수준\"')]\n"
     ]
    }
   ],
   "source": [
    "optimal_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=13, # 13 or 11\n",
    "                                                random_state=100,\n",
    "                                                update_every=1,\n",
    "                                                iterations=1000,\n",
    "                                                chunksize=100,\n",
    "                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "                                                eta='auto',\n",
    "                                                per_word_topics=True)\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "\n",
    "pprint(optimal_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get p(word|topic)\n",
    "def get_topic_word_prob(lda_model):\n",
    "    topic_word_freq = lda_model.state.get_lambda()\n",
    "    topic_word_prob = topic_word_freq / topic_word_freq.sum(axis=1)[:, None]\n",
    "\n",
    "    return topic_word_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(13, 5086)\n          교육     멀티미디어        연구        원격        자료       편집기    하이퍼미디어  \\\n0   0.002215  0.000195  0.028537  0.000005  0.000011  0.000005  0.000005   \n1   0.001012  0.000014  0.000014  0.000014  0.000014  0.000014  0.000014   \n2   0.000099  0.000099  0.000099  0.000099  0.000099  0.000099  0.000099   \n3   0.000032  0.000032  0.000032  0.000032  0.000032  0.000032  0.000032   \n4   0.000014  0.000014  0.012572  0.000014  0.000014  0.000014  0.000014   \n5   0.043205  0.000007  0.011587  0.000007  0.000007  0.000097  0.000007   \n6   0.000011  0.000011  0.002519  0.000011  0.003488  0.000011  0.000011   \n7   0.000018  0.004570  0.001044  0.000018  0.000018  0.000018  0.000612   \n8   0.000051  0.000051  0.000051  0.000051  0.000051  0.000051  0.000051   \n9   0.000005  0.000005  0.020482  0.000005  0.009867  0.000005  0.000005   \n10  0.156253  0.000002  0.039828  0.000002  0.005235  0.000002  0.000002   \n11  0.000058  0.000058  0.000058  0.049458  0.000058  0.000058  0.000058   \n12  0.000033  0.000176  0.000033  0.000033  0.000033  0.000033  0.000033   \n\n          구현        설계       인터넷  ...       new    normal       뉴노멀        대리  \\\n0   0.000005  0.006691  0.000005  ...  0.000005  0.000005  0.000005  0.000005   \n1   0.000014  0.000014  0.000014  ...  0.000014  0.000014  0.000014  0.000014   \n2   0.000099  0.000099  0.000099  ...  0.000099  0.000099  0.000099  0.000099   \n3   0.000032  0.000032  0.000032  ...  0.000034  0.000034  0.000034  0.000034   \n4   0.000014  0.000014  0.015215  ...  0.000014  0.000014  0.000014  0.000014   \n5   0.000007  0.000008  0.000007  ...  0.000007  0.000007  0.000007  0.000007   \n6   0.007855  0.014634  0.009269  ...  0.000011  0.000011  0.000011  0.000011   \n7   0.018174  0.019684  0.000018  ...  0.000019  0.000019  0.000019  0.000019   \n8   0.000051  0.000051  0.000051  ...  0.000051  0.000051  0.000051  0.000051   \n9   0.003644  0.011095  0.000005  ...  0.000005  0.000005  0.000005  0.000005   \n10  0.000002  0.000002  0.000002  ...  0.000002  0.000002  0.000002  0.000002   \n11  0.000058  0.000058  0.000058  ...  0.000058  0.000058  0.000058  0.000058   \n12  0.000033  0.000033  0.000033  ...  0.000033  0.000033  0.000033  0.000033   \n\n          독백       파급력      바이러스      교과서별       발견과       출판사  \n0   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \n1   0.000015  0.000015  0.000014  0.000014  0.000014  0.000014  \n2   0.000099  0.000099  0.000099  0.000099  0.000099  0.000099  \n3   0.000039  0.000032  0.000032  0.000032  0.000032  0.000032  \n4   0.000014  0.000014  0.000014  0.000014  0.000014  0.000014  \n5   0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n6   0.000011  0.000011  0.000011  0.000011  0.000011  0.000011  \n7   0.000020  0.000018  0.000018  0.000018  0.000018  0.000018  \n8   0.000051  0.000052  0.000051  0.000051  0.000051  0.000051  \n9   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \n10  0.000002  0.000002  0.000002  0.000002  0.000002  0.000002  \n11  0.000058  0.000059  0.000058  0.000058  0.000058  0.000058  \n12  0.000033  0.000034  0.000034  0.000033  0.000033  0.000033  \n\n[13 rows x 5086 columns]\n"
     ]
    }
   ],
   "source": [
    "topic_word_prob = get_topic_word_prob(optimal_model)\n",
    "print(topic_word_prob.shape) # (#topics, #words)\n",
    "\n",
    "wordlist = []\n",
    "for i in range(len(id2word)):\n",
    "    #print(id2word[i])\n",
    "    wordlist.append(id2word[i])\n",
    "#print(wordlist)\n",
    "seriesWordlist = pd.Series(wordlist)\n",
    "\n",
    "topic_word = pd.DataFrame(data=topic_word_prob[0:, 0:], columns=seriesWordlist)\n",
    "\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                                 [멀티미디어, 원격, 교육, 관하, 연구]\n1                           [교육, 하이퍼미디어, 자료, 편집기, 관하, 연구]\n2                                     [인터넷, 코스웨어, 설계, 구현]\n3                               [web, 협력, 환경, 구축, 방안, 연구]\n4                                   [열리, 교육, 개별, 수업, cai]\n                              ...                        \n1144    [개정, 실, 교과서, 소프트웨어, 교육, 단원, 탐구, 비교, 분석, 개, 정, ...\n1145    [화, 이러닝, 콘텐츠, 관하, 사용자, 경험, ux, 질, 평가, 화, 이러닝, ...\n1146    [초등, 데이터, 리터러시, 함양, 위하, ai, 데이터, 과학, 교육, 프로그램,...\n1147    [초등, 예비, 교사, 위하, 소프트웨어, 교육, 대하, 온라인, 교육, 효과, 분...\n1148    [초등, 실, 교과서, 나, 소프트웨어교육, 영역, 나타나, 컴퓨팅, 사고력, 요소...\nName: kor_full, Length: 1149, dtype: object\n========= tokenization completed =========\n"
     ]
    }
   ],
   "source": [
    "tokenized2 = data['kor_full'].apply(lambda row: khaiiiTokenizer(row, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL', 'VV', 'VA', 'MM'], minLen=0))\n",
    "print(tokenized2)\n",
    "print(\"========= tokenization completed =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram candidates\n",
    "\n",
    "def get_ngrams(raw, n_range=(1,3)): # 1~n-gram 까지\n",
    "\n",
    "    def to_ngrams(words, n):\n",
    "        ngrams = []\n",
    "        for b in range(0, len(words) - n + 1):\n",
    "            ngrams.append(str(tuple(words[b:b+n])))\n",
    "        return ngrams\n",
    "\n",
    "    n_begin, n_end = n_range\n",
    "    ngram_list = []\n",
    "    \n",
    "    for n in range(n_begin, n_end + 1):\n",
    "        for ngram in to_ngrams(raw, n):\n",
    "            ngram_list.append(ngram)\n",
    "            \n",
    "    return ngram_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       [('멀티미디어',), ('원격',), ('교육',), ('관하',), ('연구',...\n1       [('교육',), ('하이퍼미디어',), ('자료',), ('편집기',), ('관하...\n2       [('인터넷',), ('코스웨어',), ('설계',), ('구현',), ('인터넷'...\n3       [('web',), ('협력',), ('환경',), ('구축',), ('방안',),...\n4       [('열리',), ('교육',), ('개별',), ('수업',), ('cai',),...\n                              ...                        \n1144    [('개정',), ('실',), ('교과서',), ('소프트웨어',), ('교육',...\n1145    [('화',), ('이러닝',), ('콘텐츠',), ('관하',), ('사용자',)...\n1146    [('초등',), ('데이터',), ('리터러시',), ('함양',), ('위하',...\n1147    [('초등',), ('예비',), ('교사',), ('위하',), ('소프트웨어',...\n1148    [('초등',), ('실',), ('교과서',), ('나',), ('소프트웨어교육'...\nName: kor_full, Length: 1149, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ngrams = tokenized2.apply(lambda row: get_ngrams(row))\n",
    "\n",
    "print(ngrams)\n",
    "#print(type(ngrams))\n",
    "#print(type(ngrams.loc[0]))\n",
    "#print(type(ngrams.loc[0][0]))\n",
    "#ngrams.to_csv('./modi_data/ngrams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get score(l, t)\n",
    "# score = sum_w(p(w|t) * PMI(w,l|c))\n",
    "\n",
    "def get_score(unigram_counter, ngram_candidates, candidate, topic, topic_word_prob, ngram_docs):\n",
    "    def get_pmi(w, l_freq, unigram_counter, docs):\n",
    "        word = \"('\" + w +\"',)\"\n",
    "        count = 0\n",
    "\n",
    "        for doc in docs:\n",
    "            #print(doc)\n",
    "            if word in doc: \n",
    "                count += 1\n",
    "        pmi = count / (unigram_counter.loc[0, w] * l_freq)\n",
    "        return pmi\n",
    "    \n",
    "    candi_docs = []\n",
    "    #print(type(candi_docs))\n",
    "    for doc in ngram_docs:\n",
    "        if candidate in doc:\n",
    "            candi_docs.append(doc)\n",
    "    #print(candi_docs)\n",
    "\n",
    "    for i in range(len(ngram_candidates)):\n",
    "        if ngram_candidates.loc[i, '후보명'] == candidate:\n",
    "            candi_count = ngram_candidates.loc[i, 'count']\n",
    "    #print(candidate, candi_count)\n",
    "\n",
    "    score = 0\n",
    "    for word in unigram_counter.columns:\n",
    "        tw_prob = topic_word_prob.loc[topic, word]\n",
    "        pmi = get_pmi(word, candi_count, unigram_counter, candi_docs)\n",
    "        score += tw_prob * pmi\n",
    "\n",
    "    return round(score * 1000, 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nc = pd.read_excel(\"./modi_data/ngram_candidates.xlsx\")\n",
    "uc = pd.read_excel(\"./modi_data/unigram_counter.xlsx\")\n",
    "nc = nc.drop(['Unnamed: 0'], axis=1)\n",
    "uc = uc.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "#print(nc.columns[0])\n",
    "#print(nc.loc[0, '후보명'])\n",
    "#print(topic_word.loc[0, '교육'])\n",
    "#score1 = get_score(uc, nc, nc.loc[21, '후보명'], 0, topic_word, ngrams)\n",
    "\n",
    "#print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "topic0\n",
      "topic1\n",
      "topic2\n",
      "topic3\n",
      "topic4\n",
      "topic5\n",
      "topic6\n",
      "topic7\n",
      "topic8\n",
      "topic9\n",
      "topic10\n",
      "topic11\n",
      "topic12\n",
      "         0        1        2        3        4        5        6        7   \\\n",
      "0   0.17263  0.22817  0.20887  0.08939  0.52270  0.61278  0.17654  0.50033   \n",
      "1   0.03081  0.18426  0.21663  0.07855  0.98509  0.54752  0.19194  0.37957   \n",
      "2   0.07492  0.42676  0.51182  0.42490  0.47892  0.31328  0.13022  0.85102   \n",
      "3   0.13085  0.31231  0.18703  0.07584  0.43160  0.21659  0.24813  0.40945   \n",
      "4   0.15167  0.20995  0.10571  0.24286  0.55487  1.19974  0.19807  0.46585   \n",
      "5   0.04707  0.07205  0.11746  0.06334  0.54650  0.96316  0.11539  0.36678   \n",
      "6   0.12145  0.25256  0.39088  0.07162  1.02844  0.32443  0.16169  0.55452   \n",
      "7   0.11584  0.31606  0.32396  0.15760  0.46091  0.14183  0.08214  0.50978   \n",
      "8   0.03920  0.28063  0.22725  0.47682  0.66137  0.54381  0.19198  0.47954   \n",
      "9   0.11646  0.22093  0.18979  0.06557  0.47885  0.34552  0.15357  0.46641   \n",
      "10  0.10963  0.21840  0.17108  0.08647  0.51755  0.37831  0.20924  0.49953   \n",
      "11  0.07062  0.70057  0.41451  0.28950  0.65931  1.76346  0.41900  0.28797   \n",
      "12  0.07146  0.36846  0.33282  0.09392  0.44095  0.34967  0.14384  0.46835   \n",
      "\n",
      "         8        9   ...       90       91       92       93       94  \\\n",
      "0   0.30661  0.30012  ...  0.16444  0.43863  0.25448  0.11898  0.10932   \n",
      "1   0.34153  0.59599  ...  0.07933  0.62742  0.06273  0.04215  0.04896   \n",
      "2   0.42590  0.22203  ...  0.05244  0.19497  0.21581  0.27746  0.15092   \n",
      "3   0.41445  0.54431  ...  0.14081  0.36367  0.14851  0.03024  0.09090   \n",
      "4   0.18663  0.13235  ...  0.09635  0.39495  0.12333  0.35443  0.08901   \n",
      "5   0.66844  0.32257  ...  0.04471  0.58434  0.09321  0.04223  0.04400   \n",
      "6   0.23526  0.31773  ...  0.11613  0.32516  0.22437  0.13433  0.09771   \n",
      "7   0.31642  0.26948  ...  0.15456  0.27334  0.33481  0.07692  0.07240   \n",
      "8   0.41985  0.06851  ...  0.02685  0.60134  0.18328  0.26214  0.15152   \n",
      "9   0.23362  0.44373  ...  0.15640  0.28510  0.23660  0.09934  0.08884   \n",
      "10  0.28852  0.54405  ...  0.17451  0.35200  0.14984  0.10873  0.12089   \n",
      "11  0.16682  0.33187  ...  0.09847  0.27465  0.36900  0.21767  0.11181   \n",
      "12  0.29715  0.23365  ...  0.21633  0.44422  0.33852  0.21239  0.07158   \n",
      "\n",
      "         95       96       97       98       99  \n",
      "0   0.50169  0.44382  0.23902  0.59913  0.21012  \n",
      "1   0.36307  0.27570  0.38350  0.36559  0.07261  \n",
      "2   0.64436  0.45361  0.24169  0.42190  0.21651  \n",
      "3   0.40496  0.45842  0.33916  0.28282  0.19208  \n",
      "4   0.41770  0.31423  0.14479  0.51322  0.10665  \n",
      "5   0.32201  0.17791  0.19771  0.52932  0.05977  \n",
      "6   0.51122  0.42918  0.23789  0.35036  0.15607  \n",
      "7   0.66930  0.95606  0.16025  0.31938  0.12966  \n",
      "8   0.51712  0.48342  0.05135  0.50738  0.28097  \n",
      "9   0.59449  0.49710  0.34863  0.41427  0.17829  \n",
      "10  0.44425  0.30047  0.32734  0.36927  0.19831  \n",
      "11  0.55681  0.65202  0.20249  0.32254  0.26573  \n",
      "12  0.74188  0.41303  0.20372  0.35103  0.10171  \n",
      "\n",
      "[13 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# for all topics\n",
    "score_full = pd.DataFrame() # (topic, l_index)\n",
    "for j in range(13): # 11 or 13\n",
    "    score0 = []\n",
    "    for i in range(len(nc)):\n",
    "        score = get_score(uc, nc, nc.loc[i, '후보명'], j, topic_word, ngrams)\n",
    "        score0.append(score)\n",
    "        #score0[nc.loc[i, '후보명']] = score\n",
    "    score_full = score_full.append(pd.Series(score0), ignore_index=True)\n",
    "    #score0 = sorted(score0.items(), key=(lambda x:x[1]), reverse=True)\n",
    "    #score0 = pd.DataFrame.from_dict(score0, orient='index')\n",
    "    #score0.to_excel('./final_data/topic' + str(j) + '_candidates.xlsx')\n",
    "    print('topic'+str(j))\n",
    "\n",
    "print(score_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_full.to_excel('./final_data/topic_full_candidates.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    ('사이버', '가', '정학습')  ('동', '영', '상')  ('애', '플리케이션')  ('로봇', '보조', '학습')  \\\n0              0.150130         0.153942        0.142434            0.045078   \n1              0.005356         0.109117        0.150355            0.034012   \n2              0.050385         0.356669        0.451695            0.387578   \n3              0.107480         0.239835        0.120139            0.031245   \n4              0.128734         0.135343        0.037125            0.201745   \n5              0.021955        -0.005430        0.049119            0.018485   \n6              0.097884         0.178840        0.328236            0.026938   \n7              0.092157         0.243663        0.259921            0.114709   \n8              0.013921         0.207495        0.161197            0.440579   \n9              0.092790         0.146551        0.122956            0.020761   \n10             0.085818         0.143969        0.103856            0.042097   \n11             0.045995         0.636184        0.352358            0.249357   \n12             0.046853         0.297155        0.268966            0.049702   \n\n    ('차', '산업', '혁명')  ('대응', '표본', 't')  ('체계', '문헌', '고찰')  \\\n0            0.371776           0.465128            0.129765   \n1            0.843799           0.398508            0.145486   \n2            0.327084           0.159388            0.082480   \n3            0.278778           0.060684            0.202846   \n4            0.404616           1.064316            0.151743   \n5            0.396072           0.822807            0.067341   \n6            0.888052           0.170770            0.114605   \n7            0.308699          -0.015634            0.033398   \n8            0.513335           0.394721            0.145526   \n9            0.327012           0.192300            0.106316   \n10           0.366519           0.225773            0.163146   \n11           0.511232           1.639780            0.377276   \n12           0.288323           0.196536            0.096384   \n\n    ('목적', '달성', '위하')  ('computational', 'thinking')  ('정보교육', '학', '회')  \\\n0             0.380772                       0.223389            0.216239   \n1             0.257496                       0.259037            0.518273   \n2             0.738768                       0.345165            0.136522   \n3             0.287999                       0.333476            0.465517   \n4             0.345574                       0.100910            0.044974   \n5             0.244440                       0.592758            0.239157   \n6             0.436091                       0.150553            0.234216   \n7             0.390419                       0.233404            0.184961   \n8             0.359549                       0.338989           -0.020196   \n9             0.346146                       0.148879            0.362841   \n10            0.379956                       0.204923            0.465251   \n11            0.163988                       0.080687            0.248651   \n12            0.348126                       0.213732            0.148385   \n\n    ...  ('통신', '기술', '활용')  ('초점', '맞추')  ('전자', '책')  ('마', '스마트폰', '중독')  \\\n0   ...            0.136171      0.340273     0.202813             0.080271   \n1   ...            0.049288      0.532996     0.007068             0.001840   \n2   ...            0.021838      0.091536     0.163337             0.242053   \n3   ...            0.112049      0.263751     0.094635            -0.010318   \n4   ...            0.066663      0.295683     0.068931             0.320626   \n5   ...            0.013947      0.489018     0.038183             0.001922   \n6   ...            0.086855      0.224439     0.172076             0.095941   \n7   ...            0.126086      0.171539     0.284817             0.037335   \n8   ...           -0.004285      0.506372     0.130130             0.226414   \n9   ...            0.127964      0.183544     0.184561             0.060222   \n10  ...            0.146451      0.251838     0.095993             0.069807   \n11  ...            0.068827      0.172876     0.319719             0.181017   \n12  ...            0.189142      0.345979     0.288604             0.175627   \n\n    ('정보', '통신', '윤리')  ('다음', '같')  ('간', '상호', '작용')  ('학습', '방법', '평가')  \\\n0             0.085600     0.372791           0.331088            0.179884   \n1             0.023983     0.231283           0.159465            0.327374   \n2             0.128067     0.518433           0.341082            0.182610   \n3             0.066797     0.274045           0.345992            0.282110   \n4             0.064867     0.287051           0.198798            0.083691   \n5             0.018920     0.189367           0.059638            0.137714   \n6             0.073749     0.382519           0.316143            0.178731   \n7             0.047911     0.543893           0.853999            0.099473   \n8             0.128680     0.388542           0.371513           -0.011696   \n9             0.064694     0.467524           0.385478            0.291778   \n10            0.097411     0.314154           0.184751            0.270044   \n11            0.088142     0.429059           0.543625            0.142593   \n12            0.047074     0.617985           0.299656            0.143849   \n\n    ('학년', '학생', '명')  ('통신', '윤리', '의식')  \n0            0.500233            0.169321  \n1            0.261827            0.028946  \n2            0.319310            0.175844  \n3            0.177333            0.150905  \n4            0.412533            0.063695  \n5            0.428968            0.015839  \n6            0.246280            0.114145  \n7            0.214654            0.087185  \n8            0.406571            0.241647  \n9            0.311521            0.136828  \n10           0.265584            0.157265  \n11           0.217880            0.226089  \n12           0.246964            0.058652  \n\n[13 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# score'(l,t) = score(l,t) - alpha(변별성계수) * avg(score(l, t제외))\n",
    "alpha = 0.25\n",
    "score_final = pd.DataFrame() # (t, l)\n",
    "\n",
    "for i in range(len(nc)):\n",
    "    score_ = []\n",
    "    for t in range(13): # 11 or 13\n",
    "        score = score_full.loc[t, i] #score(l, t)\n",
    "        score_list = [s for j, s in enumerate(score_full[i]) if j != t]\n",
    "        avg = sum(score_list) / len(score_list)\n",
    "        score_.append(score - alpha * avg)\n",
    "    score_final[nc.loc[i, '후보명']] = score_\n",
    "print(score_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    #print(score_final.loc[i]) #(100, 1)\n",
    "    s = score_final.loc[i].sort_values(axis=0, ascending=False)\n",
    "    #print(s)\n",
    "    s.to_excel('./final_data/topic' + str(i) + '_candidates.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get score(l, t)\n",
    "# score = sum_w(p(w|t) * PMI(w,l|c))\n",
    "\"\"\"\n",
    "def get_score(unigram_counter, ngram_candidates, candidate, topic, topic_word_prob, ngram_docs):\n",
    "    def get_pmi(w, l, l_freq, unigram_counter, docs):\n",
    "        word = \"('\" + w +\"',)\"\n",
    "        #print(word)\n",
    "        count = 0\n",
    "\n",
    "        for doc in docs:\n",
    "            #print(doc)\n",
    "            if word in doc and l in doc:#and word in doc:\n",
    "                #print('yesss')\n",
    "                count += 1\n",
    "\n",
    "        pmi = count / (unigram_counter.loc[0, w] * l_freq)\n",
    "        return pmi\n",
    "    \n",
    "    for i in range(len(ngram_candidates)):\n",
    "        if ngram_candidates.loc[i, '후보명'] == candidate:\n",
    "            candi_count = ngram_candidates.loc[i, 'count']\n",
    "    print(candidate, candi_count)\n",
    "\n",
    "    score = 0\n",
    "    for word in unigram_counter.columns:\n",
    "        tw_prob = topic_word_prob.loc[topic, word]\n",
    "        pmi = get_pmi(word, candidate, candi_count, unigram_counter, ngram_docs)\n",
    "        score += tw_prob * pmi\n",
    "\n",
    "    return score\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "ModuleNotFoundError",
     "traceback": [
      "Error: ModuleNotFoundError",
      "at b.parseConnectInfo (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:486235)",
      "at b.connectToLocal (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:486838)",
      "at async b.connect (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:484715)",
      "at async b.startDebugSession (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:483862)",
      "at async k.submitCode (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:32:585464)",
      "at async k.handleRunByLine (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:9:173871)"
     ]
    }
   ],
   "source": [
    "# get PMI(word, 후보명(l)|문맥(c))\n",
    "# PMI = (#(w,l)) / (#w * #l)\n",
    "\"\"\"\n",
    "def get_pmi(unigram_counter, ngram_candidates, ngram_docs):\n",
    "    dfPMI = pd.DataFrame()\n",
    "    pmi_list = []\n",
    "\n",
    "    def get_wl_count(word, candidate, docs):\n",
    "        word = '(' + word + ',)'\n",
    "        count = 0\n",
    "\n",
    "        for doc in docs:\n",
    "            if candidate in doc and word in doc:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    for i, l in enumerate(ngram_candidates['후보명']):\n",
    "        for w in unigram_counter.columns:\n",
    "            pmi = get_wl_count(w, l, ngram_docs) / (unigram_counter.loc[0, w] * ngram_candidates.loc[i, 'count'])\n",
    "            pmi_list.append(pmi) \n",
    "            print('word')   \n",
    "        dfPMI.append(pmi_list)\n",
    "        pmi_list = []\n",
    "        print('5000')\n",
    "\n",
    "    dfPMI.columns = unigram_counter.columns\n",
    "\n",
    "    return dfPMI\n",
    "    \"\"\""
   ]
  }
 ]
}