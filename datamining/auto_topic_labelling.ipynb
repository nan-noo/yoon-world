{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from khaiii import KhaiiiApi\n",
    "import gensim\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   no  year                     title                      kor_full\n",
       "0   1  1997         멀티미디어 원격교육에 관한 연구         멀티미디어 원격교육에 관한 연구    \n",
       "1   2  1997  교육용 하이퍼미디어 자료 편집기에 관한 연구  교육용 하이퍼미디어 자료 편집기에 관한 연구    \n",
       "2   3  1997     인터넷 기반의 코스웨어의 설계 및 구현     인터넷 기반의 코스웨어의 설계 및 구현    \n",
       "3   4  1997     Web에서의 협력 환경 구축 방안 연구     Web에서의 협력 환경 구축 방안 연구    \n",
       "4   5  1997        열린교육에서의 개별화수업과 CAI        열린교육에서의 개별화수업과 CAI    "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>no</th>\n      <th>year</th>\n      <th>title</th>\n      <th>kor_full</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1997</td>\n      <td>멀티미디어 원격교육에 관한 연구</td>\n      <td>멀티미디어 원격교육에 관한 연구</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1997</td>\n      <td>교육용 하이퍼미디어 자료 편집기에 관한 연구</td>\n      <td>교육용 하이퍼미디어 자료 편집기에 관한 연구</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1997</td>\n      <td>인터넷 기반의 코스웨어의 설계 및 구현</td>\n      <td>인터넷 기반의 코스웨어의 설계 및 구현</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1997</td>\n      <td>Web에서의 협력 환경 구축 방안 연구</td>\n      <td>Web에서의 협력 환경 구축 방안 연구</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1997</td>\n      <td>열린교육에서의 개별화수업과 CAI</td>\n      <td>열린교육에서의 개별화수업과 CAI</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv(\"./modi_data/kor_full.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWordList = pd.read_excel(\"./khaiii_word_cor.xlsx\")\n",
    "dfWordList2 = pd.read_excel(\"./khaiii_word_cor_etc.xlsx\")\n",
    "#print(dfWordList2)\n",
    "\n",
    "dfWordDel = dfWordList[dfWordList[\"수정\"] == \"삭제\"]\n",
    "dfWordMod = dfWordList[dfWordList[\"수정\"] != \"삭제\"]\n",
    "dfWordDiv = dfWordList2\n",
    "#print(dfWordMod)\n",
    "\n",
    "seriesDelete = dfWordDel[\"기존\"]\n",
    "stopword = []\n",
    "for word in seriesDelete.values:\n",
    "    stopword.append(word)\n",
    "#print(stopword)\n",
    "\n",
    "seriesModify = dfWordMod[\"기존\"]\n",
    "modiword = []\n",
    "for word in seriesModify.values:\n",
    "    modiword.append(word)\n",
    "#print(len(modiword))\n",
    "\n",
    "seriesModify2 = dfWordMod[\"수정\"]\n",
    "modiword2 = []\n",
    "for word in seriesModify2.values:\n",
    "    modiword2.append(word)\n",
    "#print(len(modiword2))\n",
    "\n",
    "seriesDivide = dfWordDiv[\"기존\"]\n",
    "divword = []\n",
    "for word in seriesDivide.values:\n",
    "    divword.append(word)\n",
    "#print(divword)\n",
    "#print(len(divword))\n",
    "\n",
    "seriesDivide2 = dfWordDiv[\"수정\"]\n",
    "divword2 = []\n",
    "for words in seriesDivide2.values:\n",
    "    divword2.append(words.split(', '))\n",
    "#print(divword2)\n",
    "#print(len(divword2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KhaiiiApi()\n",
    "def khaiiiTokenizer(raw, stopword=stopword, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL'], minLen=1): # 일반명사 고유명사 의존명사 대명사 수사 외국어\n",
    "    list = []\n",
    "    skip = 0\n",
    "\n",
    "    for word in api.analyze(raw): #raw data\n",
    "        #print(word)\n",
    "        \n",
    "        for i, morph in enumerate(word.morphs):\n",
    "            #print(morph.lex)\n",
    "            if skip == 1: \n",
    "                #print(morph.lex) # '지능'\n",
    "                skip = 0\n",
    "                continue\n",
    "\n",
    "            if morph.lex == '인공' and i+1 < len(word.morphs) and word.morphs[i+1].lex == \"지능\":\n",
    "                #print(morph.lex + word.morphs[i+1].lex) # 인공지능\n",
    "                list.append(morph.lex + word.morphs[i+1].lex)\n",
    "                skip = 1\n",
    "                continue\n",
    "\n",
    "            if len(morph.lex) > minLen and morph.tag in pos and morph.lex not in stopword: \n",
    "                if morph.tag == 'SL':\n",
    "                    morph.lex = morph.lex.lower()\n",
    "                if morph.lex in divword:\n",
    "                    morph.lex = divword2[divword.index(morph.lex)]\n",
    "                    list.extend(morph.lex)\n",
    "                elif morph.lex in modiword:\n",
    "                    morph.lex = modiword2[modiword.index(morph.lex)]\n",
    "                    list.append(morph.lex)\n",
    "                else: list.append(morph.lex)\n",
    "                \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                                     [멀티미디어, 원격, 교육, 연구]\n1                               [교육, 하이퍼미디어, 자료, 편집기, 연구]\n2                                     [인터넷, 코스웨어, 설계, 구현]\n3                               [web, 협력, 환경, 구축, 방안, 연구]\n4                                       [교육, 개별, 수업, cai]\n                              ...                        \n1144    [개정, 교과서, 소프트웨어, 교육, 단원, 탐구, 비교, 분석, 교육, 과정, 교...\n1145    [이러닝, 콘텐츠, 사용자, 경험, ux, 평가, 이러닝, 대리, 상호, 작용, 사...\n1146    [초등, 데이터, 리터러시, 함양, ai, 데이터, 과학, 교육, 프로그램, 개발,...\n1147    [초등, 예비, 교사, 소프트웨어, 교육, 온라인, 교육, 효과, 분석, 소프트웨어...\n1148    [초등, 교과서, 소프트웨어교육, 영역, 컴퓨팅, 사고력, 요소, 분석, 소프트웨어...\nName: kor_full, Length: 1149, dtype: object\n========= tokenization completed =========\n"
     ]
    }
   ],
   "source": [
    "tokenized = data[\"kor_full\"].apply(lambda row: khaiiiTokenizer(row))\n",
    "print(tokenized)\n",
    "#tokenized.to_csv(\"./modi_data/token_khaiii.csv\")\n",
    "print(\"========= tokenization completed =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# words in total :  5086\n# documents :  1149\n"
     ]
    }
   ],
   "source": [
    "#lda\n",
    "id2word = gensim.corpora.Dictionary(tokenized)\n",
    "\n",
    "corpus=[id2word.doc2bow(text) for text in tokenized]\n",
    "#print(\"id2word for each document : \", corpus)\n",
    "print(\"# words in total : \", len(id2word))\n",
    "print(\"# documents : \", len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0,\n  '0.072*\"수업\" + 0.052*\"활용\" + 0.050*\"문제\" + 0.041*\"학생\" + 0.041*\"대상\" + 0.040*\"효과\" '\n  '+ 0.036*\"적용\" + 0.029*\"연구\" + 0.027*\"모형\" + 0.026*\"중심\"'),\n (1,\n  '0.120*\"인공지능\" + 0.094*\"ai\" + 0.078*\"데이터\" + 0.078*\"창의\" + 0.071*\"알고리즘\" + '\n  '0.040*\"융합\" + 0.037*\"프로그램\" + 0.028*\"모델\" + 0.026*\"탐색\" + 0.020*\"분야\"'),\n (2,\n  '0.138*\"측정\" + 0.072*\"정도\" + 0.067*\"it\" + 0.036*\"문서\" + 0.030*\"타당도\" + '\n  '0.030*\"산출\" + 0.021*\"범주\" + 0.015*\"xml\" + 0.013*\"상관관계\" + 0.011*\"밀접\"'),\n (3,\n  '0.318*\"평가\" + 0.078*\"유형\" + 0.060*\"수행\" + 0.042*\"플랫폼\" + 0.033*\"단원\" + '\n  '0.029*\"이러닝\" + 0.027*\"절차\" + 0.021*\"발표\" + 0.021*\"관찰\" + 0.017*\"iptv\"'),\n (4,\n  '0.117*\"로봇\" + 0.081*\"영향\" + 0.047*\"분석\" + 0.040*\"교과서\" + 0.033*\"유의미\" + '\n  '0.029*\"빅데이터\" + 0.028*\"긍정\" + 0.027*\"사용\" + 0.026*\"연수\" + 0.025*\"통계\"'),\n (5,\n  '0.106*\"컴퓨팅\" + 0.105*\"프로그래밍\" + 0.087*\"사고력\" + 0.046*\"프로그램\" + 0.043*\"교육\" + '\n  '0.039*\"초등\" + 0.024*\"사고\" + 0.023*\"게임\" + 0.022*\"소프트웨어교육\" + 0.021*\"개발\"'),\n (6,\n  '0.060*\"시스템\" + 0.046*\"온라인\" + 0.041*\"집단\" + 0.032*\"확인\" + 0.029*\"기준\" + '\n  '0.028*\"이용\" + 0.025*\"전문가\" + 0.024*\"학생\" + 0.020*\"산업\" + 0.018*\"지원\"'),\n (7,\n  '0.065*\"디지털\" + 0.062*\"스크래치\" + 0.059*\"환경\" + 0.032*\"상호\" + 0.027*\"작용\" + '\n  '0.022*\"자동\" + 0.021*\"구체\" + 0.021*\"정책\" + 0.020*\"설계\" + 0.019*\"사용자\"'),\n (8,\n  '0.173*\"검사\" + 0.060*\"지능\" + 0.048*\"문항\" + 0.043*\"진로\" + 0.039*\"선행\" + 0.037*\"진단\" '\n  '+ 0.033*\"보조\" + 0.024*\"직업\" + 0.023*\"오류\" + 0.020*\"다중\"'),\n (9,\n  '0.169*\"학습\" + 0.043*\"학습자\" + 0.039*\"교수\" + 0.034*\"활동\" + 0.020*\"연구\" + '\n  '0.018*\"요소\" + 0.017*\"단계\" + 0.016*\"개발\" + 0.014*\"이해\" + 0.014*\"방법\"'),\n (10,\n  '0.156*\"교육\" + 0.040*\"연구\" + 0.037*\"분석\" + 0.035*\"초등\" + 0.032*\"정보\" + 0.028*\"과정\" '\n  '+ 0.028*\"sw\" + 0.027*\"교사\" + 0.020*\"컴퓨터\" + 0.018*\"소프트웨어\"'),\n (11,\n  '0.089*\"개정\" + 0.061*\"지속\" + 0.049*\"원격\" + 0.048*\"국내\" + 0.047*\"발문\" + 0.036*\"대응\" '\n  '+ 0.032*\"동향\" + 0.027*\"우수\" + 0.026*\"어플리케이션\" + 0.025*\"저작\"'),\n (12,\n  '0.122*\"ict\" + 0.076*\"활용\" + 0.074*\"능력\" + 0.061*\"리터러시\" + 0.047*\"스마트폰\" + '\n  '0.031*\"강의\" + 0.028*\"학기\" + 0.022*\"학생\" + 0.020*\"sns\" + 0.019*\"수준\"')]\n"
     ]
    }
   ],
   "source": [
    "a = int(input(\"set the number of topics \"))  # 13 or 11\n",
    "optimal_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=a,\n",
    "                                                random_state=100,\n",
    "                                                update_every=1,\n",
    "                                                iterations=1000,\n",
    "                                                chunksize=100,\n",
    "                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "                                                eta='auto',\n",
    "                                                per_word_topics=True)\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "\n",
    "pprint(optimal_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get p(word|topic)\n",
    "def get_topic_word_prob(lda_model):\n",
    "    topic_word_freq = lda_model.state.get_lambda()\n",
    "    topic_word_prob = topic_word_freq / topic_word_freq.sum(axis=1)[:, None]\n",
    "\n",
    "    return topic_word_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(13, 5086)\n          교육     멀티미디어        연구        원격        자료       편집기    하이퍼미디어  \\\n0   0.002215  0.000195  0.028537  0.000005  0.000011  0.000005  0.000005   \n1   0.001012  0.000014  0.000014  0.000014  0.000014  0.000014  0.000014   \n2   0.000099  0.000099  0.000099  0.000099  0.000099  0.000099  0.000099   \n3   0.000032  0.000032  0.000032  0.000032  0.000032  0.000032  0.000032   \n4   0.000014  0.000014  0.012572  0.000014  0.000014  0.000014  0.000014   \n5   0.043205  0.000007  0.011587  0.000007  0.000007  0.000097  0.000007   \n6   0.000011  0.000011  0.002519  0.000011  0.003488  0.000011  0.000011   \n7   0.000018  0.004570  0.001044  0.000018  0.000018  0.000018  0.000612   \n8   0.000051  0.000051  0.000051  0.000051  0.000051  0.000051  0.000051   \n9   0.000005  0.000005  0.020482  0.000005  0.009867  0.000005  0.000005   \n10  0.156253  0.000002  0.039828  0.000002  0.005235  0.000002  0.000002   \n11  0.000058  0.000058  0.000058  0.049458  0.000058  0.000058  0.000058   \n12  0.000033  0.000176  0.000033  0.000033  0.000033  0.000033  0.000033   \n\n          구현        설계       인터넷  ...       new    normal       뉴노멀        대리  \\\n0   0.000005  0.006691  0.000005  ...  0.000005  0.000005  0.000005  0.000005   \n1   0.000014  0.000014  0.000014  ...  0.000014  0.000014  0.000014  0.000014   \n2   0.000099  0.000099  0.000099  ...  0.000099  0.000099  0.000099  0.000099   \n3   0.000032  0.000032  0.000032  ...  0.000034  0.000034  0.000034  0.000034   \n4   0.000014  0.000014  0.015215  ...  0.000014  0.000014  0.000014  0.000014   \n5   0.000007  0.000008  0.000007  ...  0.000007  0.000007  0.000007  0.000007   \n6   0.007855  0.014634  0.009269  ...  0.000011  0.000011  0.000011  0.000011   \n7   0.018174  0.019684  0.000018  ...  0.000019  0.000019  0.000019  0.000019   \n8   0.000051  0.000051  0.000051  ...  0.000051  0.000051  0.000051  0.000051   \n9   0.003644  0.011095  0.000005  ...  0.000005  0.000005  0.000005  0.000005   \n10  0.000002  0.000002  0.000002  ...  0.000002  0.000002  0.000002  0.000002   \n11  0.000058  0.000058  0.000058  ...  0.000058  0.000058  0.000058  0.000058   \n12  0.000033  0.000033  0.000033  ...  0.000033  0.000033  0.000033  0.000033   \n\n          독백       파급력      바이러스      교과서별       발견과       출판사  \n0   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \n1   0.000015  0.000015  0.000014  0.000014  0.000014  0.000014  \n2   0.000099  0.000099  0.000099  0.000099  0.000099  0.000099  \n3   0.000039  0.000032  0.000032  0.000032  0.000032  0.000032  \n4   0.000014  0.000014  0.000014  0.000014  0.000014  0.000014  \n5   0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n6   0.000011  0.000011  0.000011  0.000011  0.000011  0.000011  \n7   0.000020  0.000018  0.000018  0.000018  0.000018  0.000018  \n8   0.000051  0.000052  0.000051  0.000051  0.000051  0.000051  \n9   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \n10  0.000002  0.000002  0.000002  0.000002  0.000002  0.000002  \n11  0.000058  0.000059  0.000058  0.000058  0.000058  0.000058  \n12  0.000033  0.000034  0.000034  0.000033  0.000033  0.000033  \n\n[13 rows x 5086 columns]\n"
     ]
    }
   ],
   "source": [
    "topic_word_prob = get_topic_word_prob(optimal_model)\n",
    "print(topic_word_prob.shape) # (#topics, #words)\n",
    "\n",
    "wordlist = []\n",
    "for i in range(len(id2word)):\n",
    "    #print(id2word[i])\n",
    "    wordlist.append(id2word[i])\n",
    "#print(wordlist)\n",
    "seriesWordlist = pd.Series(wordlist)\n",
    "\n",
    "topic_word = pd.DataFrame(data=topic_word_prob[0:, 0:], columns=seriesWordlist)\n",
    "\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                              [멀티미디어, 원격, 교육, 관하, ㄴ, 연구]\n1                        [교육, 하이퍼미디어, 자료, 편집기, 관하, ㄴ, 연구]\n2                               [인터넷, 의, 코스웨어, 의, 설계, 구현]\n3                            [web, 의, 협력, 환경, 구축, 방안, 연구]\n4                             [열리, ㄴ, 교육, 의, 개별, 수업, cai]\n                              ...                        \n1144    [개정, 실, 교과서, 소프트웨어, 교육, 단원, 탐구, 비교, 분석, 개, 정, ...\n1145    [화, 이러닝, 콘텐츠, 관하, ㄴ, 사용자, 경험, ux, 질, 평가, 화, 이러...\n1146    [초등, 의, 데이터, 리터러시, 함양, 위하, ㄴ, ai, 데이터, 과학, 교육,...\n1147    [초등, 예비, 교사, 위하, ㄴ, 소프트웨어, 교육, 대하, ㄴ, 온라인, 교육,...\n1148    [초등, 실, 교과서, 나, 의, 소프트웨어교육, 영역, 나타나, ㄴ, 컴퓨팅, 사...\nName: kor_full, Length: 1149, dtype: object\n========= tokenization completed =========\n"
     ]
    }
   ],
   "source": [
    "tokenized2 = data['kor_full'].apply(lambda row: khaiiiTokenizer(row, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL', 'VV', 'VA','MM', 'ETM', 'JKG'], minLen=0))\n",
    "print(tokenized2)\n",
    "print(\"========= tokenization completed =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram candidates\n",
    "\n",
    "def get_ngrams(raw, n_range=(1,3)): # 1~n-gram 까지\n",
    "\n",
    "    def to_ngrams(words, n):\n",
    "        ngrams = []\n",
    "        for b in range(0, len(words) - n + 1):\n",
    "            ngrams.append(str(tuple(words[b:b+n])))\n",
    "        return ngrams\n",
    "\n",
    "    n_begin, n_end = n_range\n",
    "    ngram_list = []\n",
    "    \n",
    "    for n in range(n_begin, n_end + 1):\n",
    "        for ngram in to_ngrams(raw, n):\n",
    "            ngram_list.append(ngram)\n",
    "            \n",
    "    return ngram_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       [('멀티미디어',), ('원격',), ('교육',), ('관하',), ('ㄴ',)...\n1       [('교육',), ('하이퍼미디어',), ('자료',), ('편집기',), ('관하...\n2       [('인터넷',), ('의',), ('코스웨어',), ('의',), ('설계',),...\n3       [('web',), ('의',), ('협력',), ('환경',), ('구축',), ...\n4       [('열리',), ('ㄴ',), ('교육',), ('의',), ('개별',), ('...\n                              ...                        \n1144    [('개정',), ('실',), ('교과서',), ('소프트웨어',), ('교육',...\n1145    [('화',), ('이러닝',), ('콘텐츠',), ('관하',), ('ㄴ',), ...\n1146    [('초등',), ('의',), ('데이터',), ('리터러시',), ('함양',)...\n1147    [('초등',), ('예비',), ('교사',), ('위하',), ('ㄴ',), (...\n1148    [('초등',), ('실',), ('교과서',), ('나',), ('의',), ('...\nName: kor_full, Length: 1149, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ngrams = tokenized2.apply(lambda row: get_ngrams(row))\n",
    "\n",
    "print(ngrams)\n",
    "#print(type(ngrams))\n",
    "#print(type(ngrams.loc[0]))\n",
    "#print(type(ngrams.loc[0][0]))\n",
    "#ngrams.to_csv('./modi_data/ngrams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get score(l, t)\n",
    "# score = sum_w(p(w|t) * PMI(w,l|c))\n",
    "\n",
    "def get_score(unigram_counter, ngram_candidates, candidate, topic, topic_word_prob, ngram_docs):\n",
    "    def get_pmi(w, l_freq, unigram_counter, docs):\n",
    "        word = \"('\" + w +\"',)\"\n",
    "        count = 0\n",
    "\n",
    "        for doc in docs:\n",
    "            #print(doc)\n",
    "            if word in doc: \n",
    "                count += 1\n",
    "        pmi = count / (unigram_counter.loc[0, w] * l_freq)\n",
    "        return pmi\n",
    "    \n",
    "    candi_docs = []\n",
    "    #print(type(candi_docs))\n",
    "    for doc in ngram_docs:\n",
    "        if candidate in doc:\n",
    "            candi_docs.append(doc)\n",
    "    #print(candi_docs)\n",
    "\n",
    "    for i in range(len(ngram_candidates)):\n",
    "        if ngram_candidates.loc[i, '후보명'] == candidate:\n",
    "            candi_count = ngram_candidates.loc[i, 'count']\n",
    "    #print(candidate, candi_count)\n",
    "\n",
    "    score = 0\n",
    "    for word in unigram_counter.columns:\n",
    "        tw_prob = topic_word_prob.loc[topic, word]\n",
    "        pmi = get_pmi(word, candi_count, unigram_counter, candi_docs)\n",
    "        score += tw_prob * pmi\n",
    "\n",
    "    return round(score * 1000, 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nc = pd.read_excel(\"./modi_data/ngram_candidates.xlsx\")\n",
    "uc = pd.read_excel(\"./modi_data/unigram_counter.xlsx\")\n",
    "nc = nc.drop(['Unnamed: 0'], axis=1)\n",
    "uc = uc.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "#print(nc.columns[0])\n",
    "#print(nc.loc[0, '후보명'])\n",
    "#print(topic_word.loc[0, '교육'])\n",
    "#score1 = get_score(uc, nc, nc.loc[21, '후보명'], 0, topic_word, ngrams)\n",
    "\n",
    "#print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "topic0\n",
      "topic1\n",
      "topic2\n",
      "topic3\n",
      "topic4\n",
      "topic5\n",
      "topic6\n",
      "topic7\n",
      "topic8\n",
      "topic9\n",
      "topic10\n",
      "topic11\n",
      "topic12\n",
      "         0        1        2        3        4        5        6        7   \\\n",
      "0   0.22817  0.17263  0.06272  0.20887  0.08939  0.52270  0.61278  0.17654   \n",
      "1   0.18426  0.03081  0.08933  0.21663  0.07855  0.98509  0.54752  0.19194   \n",
      "2   0.42676  0.07492  0.54875  0.51182  0.42490  0.47892  0.31328  0.13022   \n",
      "3   0.31231  0.13085  0.11354  0.18703  0.07584  0.43160  0.21659  0.24813   \n",
      "4   0.20995  0.15167  0.03297  0.10571  0.24286  0.55487  1.19974  0.19807   \n",
      "5   0.07205  0.04707  0.04011  0.11746  0.06334  0.54650  0.96316  0.11539   \n",
      "6   0.25256  0.12145  0.08606  0.39088  0.07162  1.02844  0.32443  0.16169   \n",
      "7   0.31606  0.11584  0.19908  0.32396  0.15760  0.46091  0.14183  0.08214   \n",
      "8   0.28063  0.03920  0.09008  0.22725  0.47682  0.66137  0.54381  0.19198   \n",
      "9   0.22093  0.11646  0.03985  0.18979  0.06557  0.47885  0.34552  0.15357   \n",
      "10  0.21840  0.10963  0.07646  0.17108  0.08647  0.51755  0.37831  0.20924   \n",
      "11  0.70057  0.07062  0.17479  0.41451  0.28950  0.65931  1.76346  0.41900   \n",
      "12  0.36846  0.07146  0.06073  0.33282  0.09392  0.44095  0.34967  0.14384   \n",
      "\n",
      "         8        9   ...       90       91       92       93       94  \\\n",
      "0   0.39518  0.50033  ...  0.17724  0.36274  0.54345  0.20748  0.39945   \n",
      "1   0.35247  0.37957  ...  0.08953  0.21463  0.30415  0.10357  0.25800   \n",
      "2   0.75570  0.85102  ...  0.03607  0.38383  0.91357  0.10027  0.26994   \n",
      "3   0.40704  0.40945  ...  0.07923  0.25133  0.43602  0.07090  0.19554   \n",
      "4   0.37368  0.46585  ...  0.09416  0.29380  0.59776  0.07432  0.25745   \n",
      "5   0.35310  0.36678  ...  0.10133  0.61568  0.34136  0.21557  0.29659   \n",
      "6   0.45146  0.55452  ...  0.07580  0.27291  0.41551  0.11109  0.27161   \n",
      "7   0.40780  0.50978  ...  0.08200  0.38720  0.37358  0.31602  0.27363   \n",
      "8   0.52002  0.47954  ...  0.06401  0.25514  0.52511  0.10521  0.19631   \n",
      "9   0.34583  0.46641  ...  0.21100  0.24649  0.45223  0.18105  0.39553   \n",
      "10  0.46088  0.49953  ...  0.09581  0.50235  0.46724  0.08797  0.30246   \n",
      "11  0.55114  0.28797  ...  0.06581  0.45668  0.56149  0.12963  0.52119   \n",
      "12  0.35739  0.46835  ...  0.08924  0.42183  0.59195  0.43551  0.28999   \n",
      "\n",
      "         95       96       97       98       99  \n",
      "0   0.40748  0.54618  0.25908  0.29433  0.67099  \n",
      "1   0.41315  0.33549  0.50710  0.17147  0.36845  \n",
      "2   0.50003  0.40479  0.40100  0.35473  0.58327  \n",
      "3   0.25393  0.24982  0.34469  0.27929  0.31318  \n",
      "4   0.29724  0.53367  0.15156  0.23947  0.58403  \n",
      "5   0.38426  0.58053  0.44915  0.14367  0.61651  \n",
      "6   0.40010  0.30484  0.37897  0.30832  0.42845  \n",
      "7   0.24573  0.34074  0.34910  0.52638  0.39826  \n",
      "8   0.31454  0.27438  0.04804  0.26544  0.66121  \n",
      "9   0.55242  0.53744  0.37866  0.30114  0.50826  \n",
      "10  0.48663  0.30930  0.49101  0.20504  0.47005  \n",
      "11  0.43488  0.34786  0.61630  0.35038  0.36253  \n",
      "12  0.87653  0.32093  0.25679  0.27299  0.49445  \n",
      "\n",
      "[13 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# for all topics\n",
    "score_full = pd.DataFrame() # (topic, l_index)\n",
    "for j in range(13): # 11 or 13\n",
    "    score0 = []\n",
    "    for i in range(len(nc)):\n",
    "        score = get_score(uc, nc, nc.loc[i, '후보명'], j, topic_word, ngrams)\n",
    "        score0.append(score)\n",
    "        #score0[nc.loc[i, '후보명']] = score\n",
    "    score_full = score_full.append(pd.Series(score0), ignore_index=True)\n",
    "    #score0 = sorted(score0.items(), key=(lambda x:x[1]), reverse=True)\n",
    "    #score0 = pd.DataFrame.from_dict(score0, orient='index')\n",
    "    #score0.to_excel('./final_data/topic' + str(j) + '_candidates.xlsx')\n",
    "    print('topic'+str(j))\n",
    "\n",
    "print(score_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_full.to_excel('./final_data/topic_full_candidates.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    ('동', '영', '상')  ('사이버', '가', '정학습')  ('그리', 'ㄴ', 'it')  ('애', '플리케이션')  \\\n0          0.168788             0.154630           0.036858        0.155721   \n1          0.124146             0.010447           0.063911        0.163610   \n2          0.370687             0.055292           0.530988        0.463720   \n3          0.254330             0.112154           0.088525        0.133517   \n4          0.150264             0.133321           0.006612        0.050842   \n5          0.010066             0.026978           0.013871        0.062787   \n6          0.193584             0.102597           0.060587        0.340765   \n7          0.258142             0.096894           0.175490        0.272729   \n8          0.222122             0.018976           0.064673        0.174407   \n9          0.161427             0.097524           0.013606        0.136323   \n10         0.158855             0.090580           0.050826        0.117301   \n11         0.649061             0.050920           0.150795        0.364788   \n12         0.311416             0.051774           0.034834        0.281737   \n\n    ('로봇', '보조', '학습')  ('차', '산업', '혁명')  ('대응', '표본', 't')  \\\n0             0.053940           0.401961           0.494658   \n1             0.042919           0.872057           0.428310   \n2             0.395042           0.357451           0.190166   \n3             0.040164           0.309342           0.091865   \n4             0.209968           0.434667           1.091401   \n5             0.027456           0.426157           0.850878   \n6             0.035874           0.916130           0.201502   \n7             0.123287           0.339141           0.015859   \n8             0.447827           0.542942           0.424539   \n9             0.029723           0.357380           0.222944   \n10            0.050972           0.396725           0.256280   \n11            0.257385           0.540847           1.664516   \n12            0.058546           0.318848           0.227163   \n\n    ('체계', '문헌', '고찰')  ('ㄹ', '필요', '있')  ('목적', '달성', '위하')  ...  \\\n0             0.139120          0.306238            0.404684  ...   \n1             0.154776          0.262816            0.281911  ...   \n2             0.092028          0.672767            0.761219  ...   \n3             0.211903          0.318296            0.312289  ...   \n4             0.161009          0.284380            0.369629  ...   \n5             0.076951          0.263457            0.268908  ...   \n6             0.124022          0.363456            0.459777  ...   \n7             0.043147          0.319068            0.414291  ...   \n8             0.154817          0.433159            0.383547  ...   \n9             0.115767          0.256066            0.370198  ...   \n10            0.172365          0.373033            0.403870  ...   \n11            0.385621          0.464797            0.188784  ...   \n12            0.105875          0.267818            0.372171  ...   \n\n    ('플립', '러닝')  ('예비', '교원', '의')  ('분석', '그', '결과')  ('글', '쓰', '기')  \\\n0       0.159174           0.291042           0.443784         0.175295   \n1       0.070002           0.140464           0.200495         0.069653   \n2       0.015651           0.312484           0.820072         0.066298   \n3       0.059530           0.177775           0.334563         0.036439   \n4       0.074709           0.220953           0.498999         0.039915   \n5       0.081998           0.548198           0.238326         0.183520   \n6       0.056043           0.199715           0.313711         0.077298   \n7       0.062346           0.315910           0.271083         0.285644   \n8       0.044056           0.181649           0.425138         0.071320   \n9       0.193496           0.172855           0.351044         0.148424   \n10      0.076386           0.432979           0.366304         0.053793   \n11      0.045886           0.386548           0.462125         0.096147   \n12      0.069707           0.351117           0.493092         0.407125   \n\n    ('재량', '활동', '시간')  ('세기', '지식', '정보')  ('향상', '긍정', 'ㄴ')  \\\n0             0.340646            0.321489           0.470517   \n1             0.196839            0.327254           0.256315   \n2             0.208978            0.415582           0.326770   \n3             0.133337            0.165380           0.169217   \n4             0.196279            0.209412           0.457798   \n5             0.236072            0.297882           0.505439   \n6             0.210675            0.313986           0.225155   \n7             0.212729            0.157044           0.261653   \n8             0.134120            0.227000           0.194187   \n9             0.336661            0.468845           0.461631   \n10            0.242040            0.401958           0.229689   \n11            0.464415            0.349346           0.268892   \n12            0.229362            0.798357           0.241513   \n\n    ('과정', '표준', '모델')  ('상호', '작용')  ('학생', '명', '대상')  \n0             0.186207      0.237358           0.574512  \n1             0.438361      0.112450           0.266930  \n2             0.330493      0.298765           0.485330  \n3             0.273244      0.222067           0.210739  \n4             0.076895      0.181584           0.486103  \n5             0.379445      0.084187           0.519124  \n6             0.308095      0.251581           0.327930  \n7             0.277728      0.473275           0.297237  \n8            -0.028350      0.207987           0.564569  \n9             0.307780      0.244282           0.409070  \n10            0.422003      0.146580           0.370224  \n11            0.549381      0.294342           0.260912  \n12            0.183879      0.215662           0.395030  \n\n[13 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# score'(l,t) = score(l,t) - alpha(변별성계수) * avg(score(l, t제외))\n",
    "alpha = 0.2\n",
    "score_final = pd.DataFrame() # (t, l)\n",
    "\n",
    "for i in range(len(nc)):\n",
    "    score_ = []\n",
    "    for t in range(13): # 11 or 13\n",
    "        score = score_full.loc[t, i] #score(l, t)\n",
    "        score_list = [s for j, s in enumerate(score_full[i]) if j != t]\n",
    "        avg = sum(score_list) / len(score_list)\n",
    "        score_.append(score - alpha * avg)\n",
    "    score_final[nc.loc[i, '후보명']] = score_\n",
    "print(score_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    #print(score_final.loc[i]) #(100, 1)\n",
    "    s = score_final.loc[i].sort_values(axis=0, ascending=False)\n",
    "    #print(s)\n",
    "    s.to_excel('./final_data/topic' + str(i) + '_candidates.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get score(l, t)\n",
    "# score = sum_w(p(w|t) * PMI(w,l|c))\n",
    "\"\"\"\n",
    "def get_score(unigram_counter, ngram_candidates, candidate, topic, topic_word_prob, ngram_docs):\n",
    "    def get_pmi(w, l, l_freq, unigram_counter, docs):\n",
    "        word = \"('\" + w +\"',)\"\n",
    "        #print(word)\n",
    "        count = 0\n",
    "\n",
    "        for doc in docs:\n",
    "            #print(doc)\n",
    "            if word in doc and l in doc:#and word in doc:\n",
    "                #print('yesss')\n",
    "                count += 1\n",
    "\n",
    "        pmi = count / (unigram_counter.loc[0, w] * l_freq)\n",
    "        return pmi\n",
    "    \n",
    "    for i in range(len(ngram_candidates)):\n",
    "        if ngram_candidates.loc[i, '후보명'] == candidate:\n",
    "            candi_count = ngram_candidates.loc[i, 'count']\n",
    "    print(candidate, candi_count)\n",
    "\n",
    "    score = 0\n",
    "    for word in unigram_counter.columns:\n",
    "        tw_prob = topic_word_prob.loc[topic, word]\n",
    "        pmi = get_pmi(word, candidate, candi_count, unigram_counter, ngram_docs)\n",
    "        score += tw_prob * pmi\n",
    "\n",
    "    return score\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "ModuleNotFoundError",
     "traceback": [
      "Error: ModuleNotFoundError",
      "at b.parseConnectInfo (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:486235)",
      "at b.connectToLocal (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:486838)",
      "at async b.connect (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:484715)",
      "at async b.startDebugSession (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:483862)",
      "at async k.submitCode (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:32:585464)",
      "at async k.handleRunByLine (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:9:173871)"
     ]
    }
   ],
   "source": [
    "# get PMI(word, 후보명(l)|문맥(c))\n",
    "# PMI = (#(w,l)) / (#w * #l)\n",
    "\"\"\"\n",
    "def get_pmi(unigram_counter, ngram_candidates, ngram_docs):\n",
    "    dfPMI = pd.DataFrame()\n",
    "    pmi_list = []\n",
    "\n",
    "    def get_wl_count(word, candidate, docs):\n",
    "        word = '(' + word + ',)'\n",
    "        count = 0\n",
    "\n",
    "        for doc in docs:\n",
    "            if candidate in doc and word in doc:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    for i, l in enumerate(ngram_candidates['후보명']):\n",
    "        for w in unigram_counter.columns:\n",
    "            pmi = get_wl_count(w, l, ngram_docs) / (unigram_counter.loc[0, w] * ngram_candidates.loc[i, 'count'])\n",
    "            pmi_list.append(pmi) \n",
    "            print('word')   \n",
    "        dfPMI.append(pmi_list)\n",
    "        pmi_list = []\n",
    "        print('5000')\n",
    "\n",
    "    dfPMI.columns = unigram_counter.columns\n",
    "\n",
    "    return dfPMI\n",
    "    \"\"\""
   ]
  }
 ]
}