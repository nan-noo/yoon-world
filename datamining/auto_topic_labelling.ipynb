{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from khaiii import KhaiiiApi\n",
    "import gensim\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   no  year                     title                      kor_full\n",
       "0   1  1997         멀티미디어 원격교육에 관한 연구         멀티미디어 원격교육에 관한 연구    \n",
       "1   2  1997  교육용 하이퍼미디어 자료 편집기에 관한 연구  교육용 하이퍼미디어 자료 편집기에 관한 연구    \n",
       "2   3  1997     인터넷 기반의 코스웨어의 설계 및 구현     인터넷 기반의 코스웨어의 설계 및 구현    \n",
       "3   4  1997     Web에서의 협력 환경 구축 방안 연구     Web에서의 협력 환경 구축 방안 연구    \n",
       "4   5  1997        열린교육에서의 개별화수업과 CAI        열린교육에서의 개별화수업과 CAI    "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>no</th>\n      <th>year</th>\n      <th>title</th>\n      <th>kor_full</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1997</td>\n      <td>멀티미디어 원격교육에 관한 연구</td>\n      <td>멀티미디어 원격교육에 관한 연구</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1997</td>\n      <td>교육용 하이퍼미디어 자료 편집기에 관한 연구</td>\n      <td>교육용 하이퍼미디어 자료 편집기에 관한 연구</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1997</td>\n      <td>인터넷 기반의 코스웨어의 설계 및 구현</td>\n      <td>인터넷 기반의 코스웨어의 설계 및 구현</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1997</td>\n      <td>Web에서의 협력 환경 구축 방안 연구</td>\n      <td>Web에서의 협력 환경 구축 방안 연구</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1997</td>\n      <td>열린교육에서의 개별화수업과 CAI</td>\n      <td>열린교육에서의 개별화수업과 CAI</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv(\"./modi_data/kor_full.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWordList = pd.read_excel(\"./khaiii_word_cor.xlsx\")\n",
    "dfWordList2 = pd.read_excel(\"./khaiii_word_cor_etc.xlsx\")\n",
    "#print(dfWordList2)\n",
    "\n",
    "dfWordDel = dfWordList[dfWordList[\"수정\"] == \"삭제\"]\n",
    "dfWordMod = dfWordList[dfWordList[\"수정\"] != \"삭제\"]\n",
    "dfWordDiv = dfWordList2\n",
    "#print(dfWordMod)\n",
    "\n",
    "seriesDelete = dfWordDel[\"기존\"]\n",
    "stopword = []\n",
    "for word in seriesDelete.values:\n",
    "    stopword.append(word)\n",
    "#print(stopword)\n",
    "\n",
    "seriesModify = dfWordMod[\"기존\"]\n",
    "modiword = []\n",
    "for word in seriesModify.values:\n",
    "    modiword.append(word)\n",
    "#print(len(modiword))\n",
    "\n",
    "seriesModify2 = dfWordMod[\"수정\"]\n",
    "modiword2 = []\n",
    "for word in seriesModify2.values:\n",
    "    modiword2.append(word)\n",
    "#print(len(modiword2))\n",
    "\n",
    "seriesDivide = dfWordDiv[\"기존\"]\n",
    "divword = []\n",
    "for word in seriesDivide.values:\n",
    "    divword.append(word)\n",
    "#print(divword)\n",
    "#print(len(divword))\n",
    "\n",
    "seriesDivide2 = dfWordDiv[\"수정\"]\n",
    "divword2 = []\n",
    "for words in seriesDivide2.values:\n",
    "    divword2.append(words.split(', '))\n",
    "#print(divword2)\n",
    "#print(len(divword2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KhaiiiApi()\n",
    "def khaiiiTokenizer(raw, stopword=stopword, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL'], minLen=1): # 일반명사 고유명사 의존명사 대명사 수사 외국어\n",
    "    list = []\n",
    "    skip = 0\n",
    "\n",
    "    for word in api.analyze(raw): #raw data\n",
    "        #print(word)\n",
    "        \n",
    "        for i, morph in enumerate(word.morphs):\n",
    "            #print(morph.lex)\n",
    "            if skip == 1: \n",
    "                #print(morph.lex) # '지능'\n",
    "                skip = 0\n",
    "                continue\n",
    "\n",
    "            if morph.lex == '인공' and i+1 < len(word.morphs) and word.morphs[i+1].lex == \"지능\":\n",
    "                #print(morph.lex + word.morphs[i+1].lex) # 인공지능\n",
    "                list.append(morph.lex + word.morphs[i+1].lex)\n",
    "                skip = 1\n",
    "                continue\n",
    "\n",
    "            if len(morph.lex) > minLen and morph.tag in pos and morph.lex not in stopword: \n",
    "                if morph.tag == 'SL':\n",
    "                    morph.lex = morph.lex.lower()\n",
    "                if morph.lex in divword:\n",
    "                    morph.lex = divword2[divword.index(morph.lex)]\n",
    "                    list.extend(morph.lex)\n",
    "                elif morph.lex in modiword:\n",
    "                    morph.lex = modiword2[modiword.index(morph.lex)]\n",
    "                    list.append(morph.lex)\n",
    "                else: list.append(morph.lex)\n",
    "                \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                                     [멀티미디어, 원격, 교육, 연구]\n1                               [교육, 하이퍼미디어, 자료, 편집기, 연구]\n2                                     [인터넷, 코스웨어, 설계, 구현]\n3                               [web, 협력, 환경, 구축, 방안, 연구]\n4                                       [교육, 개별, 수업, cai]\n                              ...                        \n1144    [개정, 교과서, 소프트웨어, 교육, 단원, 탐구, 비교, 분석, 교육, 과정, 교...\n1145    [이러닝, 콘텐츠, 사용자, 경험, ux, 평가, 이러닝, 대리, 상호, 작용, 사...\n1146    [초등, 데이터, 리터러시, 함양, ai, 데이터, 과학, 교육, 프로그램, 개발,...\n1147    [초등, 예비, 교사, 소프트웨어, 교육, 온라인, 교육, 효과, 분석, 소프트웨어...\n1148    [초등, 교과서, 소프트웨어교육, 영역, 컴퓨팅, 사고력, 요소, 분석, 소프트웨어...\nName: kor_full, Length: 1149, dtype: object\n========= tokenization completed =========\n"
     ]
    }
   ],
   "source": [
    "tokenized = data[\"kor_full\"].apply(lambda row: khaiiiTokenizer(row))\n",
    "print(tokenized)\n",
    "#tokenized.to_csv(\"./modi_data/token_khaiii.csv\")\n",
    "print(\"========= tokenization completed =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# words in total :  5086\n# documents :  1149\n"
     ]
    }
   ],
   "source": [
    "#lda\n",
    "id2word = gensim.corpora.Dictionary(tokenized)\n",
    "\n",
    "corpus=[id2word.doc2bow(text) for text in tokenized]\n",
    "#print(\"id2word for each document : \", corpus)\n",
    "print(\"# words in total : \", len(id2word))\n",
    "print(\"# documents : \", len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0,\n  '0.072*\"수업\" + 0.052*\"활용\" + 0.050*\"문제\" + 0.041*\"학생\" + 0.041*\"대상\" + 0.040*\"효과\" '\n  '+ 0.036*\"적용\" + 0.029*\"연구\" + 0.027*\"모형\" + 0.026*\"중심\"'),\n (1,\n  '0.120*\"인공지능\" + 0.094*\"ai\" + 0.078*\"데이터\" + 0.078*\"창의\" + 0.071*\"알고리즘\" + '\n  '0.040*\"융합\" + 0.037*\"프로그램\" + 0.028*\"모델\" + 0.026*\"탐색\" + 0.020*\"분야\"'),\n (2,\n  '0.138*\"측정\" + 0.072*\"정도\" + 0.067*\"it\" + 0.036*\"문서\" + 0.030*\"타당도\" + '\n  '0.030*\"산출\" + 0.021*\"범주\" + 0.015*\"xml\" + 0.013*\"상관관계\" + 0.011*\"밀접\"'),\n (3,\n  '0.318*\"평가\" + 0.078*\"유형\" + 0.060*\"수행\" + 0.042*\"플랫폼\" + 0.033*\"단원\" + '\n  '0.029*\"이러닝\" + 0.027*\"절차\" + 0.021*\"발표\" + 0.021*\"관찰\" + 0.017*\"iptv\"'),\n (4,\n  '0.117*\"로봇\" + 0.081*\"영향\" + 0.047*\"분석\" + 0.040*\"교과서\" + 0.033*\"유의미\" + '\n  '0.029*\"빅데이터\" + 0.028*\"긍정\" + 0.027*\"사용\" + 0.026*\"연수\" + 0.025*\"통계\"'),\n (5,\n  '0.106*\"컴퓨팅\" + 0.105*\"프로그래밍\" + 0.087*\"사고력\" + 0.046*\"프로그램\" + 0.043*\"교육\" + '\n  '0.039*\"초등\" + 0.024*\"사고\" + 0.023*\"게임\" + 0.022*\"소프트웨어교육\" + 0.021*\"개발\"'),\n (6,\n  '0.060*\"시스템\" + 0.046*\"온라인\" + 0.041*\"집단\" + 0.032*\"확인\" + 0.029*\"기준\" + '\n  '0.028*\"이용\" + 0.025*\"전문가\" + 0.024*\"학생\" + 0.020*\"산업\" + 0.018*\"지원\"'),\n (7,\n  '0.065*\"디지털\" + 0.062*\"스크래치\" + 0.059*\"환경\" + 0.032*\"상호\" + 0.027*\"작용\" + '\n  '0.022*\"자동\" + 0.021*\"구체\" + 0.021*\"정책\" + 0.020*\"설계\" + 0.019*\"사용자\"'),\n (8,\n  '0.173*\"검사\" + 0.060*\"지능\" + 0.048*\"문항\" + 0.043*\"진로\" + 0.039*\"선행\" + 0.037*\"진단\" '\n  '+ 0.033*\"보조\" + 0.024*\"직업\" + 0.023*\"오류\" + 0.020*\"다중\"'),\n (9,\n  '0.169*\"학습\" + 0.043*\"학습자\" + 0.039*\"교수\" + 0.034*\"활동\" + 0.020*\"연구\" + '\n  '0.018*\"요소\" + 0.017*\"단계\" + 0.016*\"개발\" + 0.014*\"이해\" + 0.014*\"방법\"'),\n (10,\n  '0.156*\"교육\" + 0.040*\"연구\" + 0.037*\"분석\" + 0.035*\"초등\" + 0.032*\"정보\" + 0.028*\"과정\" '\n  '+ 0.028*\"sw\" + 0.027*\"교사\" + 0.020*\"컴퓨터\" + 0.018*\"소프트웨어\"'),\n (11,\n  '0.089*\"개정\" + 0.061*\"지속\" + 0.049*\"원격\" + 0.048*\"국내\" + 0.047*\"발문\" + 0.036*\"대응\" '\n  '+ 0.032*\"동향\" + 0.027*\"우수\" + 0.026*\"어플리케이션\" + 0.025*\"저작\"'),\n (12,\n  '0.122*\"ict\" + 0.076*\"활용\" + 0.074*\"능력\" + 0.061*\"리터러시\" + 0.047*\"스마트폰\" + '\n  '0.031*\"강의\" + 0.028*\"학기\" + 0.022*\"학생\" + 0.020*\"sns\" + 0.019*\"수준\"')]\n"
     ]
    }
   ],
   "source": [
    "optimal_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=id2word,\n",
    "                                                num_topics=13, # 13 or 11\n",
    "                                                random_state=100,\n",
    "                                                update_every=1,\n",
    "                                                iterations=1000,\n",
    "                                                chunksize=100,\n",
    "                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "                                                eta='auto',\n",
    "                                                per_word_topics=True)\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "\n",
    "pprint(optimal_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get p(word|topic)\n",
    "def get_topic_word_prob(lda_model):\n",
    "    topic_word_freq = lda_model.state.get_lambda()\n",
    "    topic_word_prob = topic_word_freq / topic_word_freq.sum(axis=1)[:, None]\n",
    "\n",
    "    return topic_word_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(13, 5086)\n          교육     멀티미디어        연구        원격        자료       편집기    하이퍼미디어  \\\n0   0.002215  0.000195  0.028537  0.000005  0.000011  0.000005  0.000005   \n1   0.001012  0.000014  0.000014  0.000014  0.000014  0.000014  0.000014   \n2   0.000099  0.000099  0.000099  0.000099  0.000099  0.000099  0.000099   \n3   0.000032  0.000032  0.000032  0.000032  0.000032  0.000032  0.000032   \n4   0.000014  0.000014  0.012572  0.000014  0.000014  0.000014  0.000014   \n5   0.043205  0.000007  0.011587  0.000007  0.000007  0.000097  0.000007   \n6   0.000011  0.000011  0.002519  0.000011  0.003488  0.000011  0.000011   \n7   0.000018  0.004570  0.001044  0.000018  0.000018  0.000018  0.000612   \n8   0.000051  0.000051  0.000051  0.000051  0.000051  0.000051  0.000051   \n9   0.000005  0.000005  0.020482  0.000005  0.009867  0.000005  0.000005   \n10  0.156253  0.000002  0.039828  0.000002  0.005235  0.000002  0.000002   \n11  0.000058  0.000058  0.000058  0.049458  0.000058  0.000058  0.000058   \n12  0.000033  0.000176  0.000033  0.000033  0.000033  0.000033  0.000033   \n\n          구현        설계       인터넷  ...       new    normal       뉴노멀        대리  \\\n0   0.000005  0.006691  0.000005  ...  0.000005  0.000005  0.000005  0.000005   \n1   0.000014  0.000014  0.000014  ...  0.000014  0.000014  0.000014  0.000014   \n2   0.000099  0.000099  0.000099  ...  0.000099  0.000099  0.000099  0.000099   \n3   0.000032  0.000032  0.000032  ...  0.000034  0.000034  0.000034  0.000034   \n4   0.000014  0.000014  0.015215  ...  0.000014  0.000014  0.000014  0.000014   \n5   0.000007  0.000008  0.000007  ...  0.000007  0.000007  0.000007  0.000007   \n6   0.007855  0.014634  0.009269  ...  0.000011  0.000011  0.000011  0.000011   \n7   0.018174  0.019684  0.000018  ...  0.000019  0.000019  0.000019  0.000019   \n8   0.000051  0.000051  0.000051  ...  0.000051  0.000051  0.000051  0.000051   \n9   0.003644  0.011095  0.000005  ...  0.000005  0.000005  0.000005  0.000005   \n10  0.000002  0.000002  0.000002  ...  0.000002  0.000002  0.000002  0.000002   \n11  0.000058  0.000058  0.000058  ...  0.000058  0.000058  0.000058  0.000058   \n12  0.000033  0.000033  0.000033  ...  0.000033  0.000033  0.000033  0.000033   \n\n          독백       파급력      바이러스      교과서별       발견과       출판사  \n0   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \n1   0.000015  0.000015  0.000014  0.000014  0.000014  0.000014  \n2   0.000099  0.000099  0.000099  0.000099  0.000099  0.000099  \n3   0.000039  0.000032  0.000032  0.000032  0.000032  0.000032  \n4   0.000014  0.000014  0.000014  0.000014  0.000014  0.000014  \n5   0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n6   0.000011  0.000011  0.000011  0.000011  0.000011  0.000011  \n7   0.000020  0.000018  0.000018  0.000018  0.000018  0.000018  \n8   0.000051  0.000052  0.000051  0.000051  0.000051  0.000051  \n9   0.000005  0.000005  0.000005  0.000005  0.000005  0.000005  \n10  0.000002  0.000002  0.000002  0.000002  0.000002  0.000002  \n11  0.000058  0.000059  0.000058  0.000058  0.000058  0.000058  \n12  0.000033  0.000034  0.000034  0.000033  0.000033  0.000033  \n\n[13 rows x 5086 columns]\n"
     ]
    }
   ],
   "source": [
    "topic_word_prob = get_topic_word_prob(optimal_model)\n",
    "print(topic_word_prob.shape) # (#topics, #words)\n",
    "\n",
    "wordlist = []\n",
    "for i in range(len(id2word)):\n",
    "    #print(id2word[i])\n",
    "    wordlist.append(id2word[i])\n",
    "#print(wordlist)\n",
    "seriesWordlist = pd.Series(wordlist)\n",
    "\n",
    "topic_word = pd.DataFrame(data=topic_word_prob[0:, 0:], columns=seriesWordlist)\n",
    "\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                                 [멀티미디어, 원격, 교육, 관하, 연구]\n1                           [교육, 하이퍼미디어, 자료, 편집기, 관하, 연구]\n2                                     [인터넷, 코스웨어, 설계, 구현]\n3                               [web, 협력, 환경, 구축, 방안, 연구]\n4                                   [열리, 교육, 개별, 수업, cai]\n                              ...                        \n1144    [개정, 실, 교과서, 소프트웨어, 교육, 단원, 탐구, 비교, 분석, 개, 정, ...\n1145    [화, 이러닝, 콘텐츠, 관하, 사용자, 경험, ux, 질, 평가, 화, 이러닝, ...\n1146    [초등, 데이터, 리터러시, 함양, 위하, ai, 데이터, 과학, 교육, 프로그램,...\n1147    [초등, 예비, 교사, 위하, 소프트웨어, 교육, 대하, 온라인, 교육, 효과, 분...\n1148    [초등, 실, 교과서, 나, 소프트웨어교육, 영역, 나타나, 컴퓨팅, 사고력, 요소...\nName: kor_full, Length: 1149, dtype: object\n========= tokenization completed =========\n"
     ]
    }
   ],
   "source": [
    "tokenized2 = data['kor_full'].apply(lambda row: khaiiiTokenizer(row, pos=['NNG', 'NNP', 'NNB', 'NP', 'NR', 'SL', 'VV', 'VA', 'MM'], minLen=0))\n",
    "print(tokenized2)\n",
    "print(\"========= tokenization completed =========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram candidates\n",
    "\n",
    "def get_ngrams(raw, n_range=(1,3)): # 1~n-gram 까지\n",
    "\n",
    "    def to_ngrams(words, n):\n",
    "        ngrams = []\n",
    "        for b in range(0, len(words) - n + 1):\n",
    "            ngrams.append(str(tuple(words[b:b+n])))\n",
    "        return ngrams\n",
    "\n",
    "    n_begin, n_end = n_range\n",
    "    ngram_list = []\n",
    "    \n",
    "    for n in range(n_begin, n_end + 1):\n",
    "        for ngram in to_ngrams(raw, n):\n",
    "            ngram_list.append(ngram)\n",
    "            \n",
    "    return ngram_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       [('멀티미디어',), ('원격',), ('교육',), ('관하',), ('연구',...\n1       [('교육',), ('하이퍼미디어',), ('자료',), ('편집기',), ('관하...\n2       [('인터넷',), ('코스웨어',), ('설계',), ('구현',), ('인터넷'...\n3       [('web',), ('협력',), ('환경',), ('구축',), ('방안',),...\n4       [('열리',), ('교육',), ('개별',), ('수업',), ('cai',),...\n                              ...                        \n1144    [('개정',), ('실',), ('교과서',), ('소프트웨어',), ('교육',...\n1145    [('화',), ('이러닝',), ('콘텐츠',), ('관하',), ('사용자',)...\n1146    [('초등',), ('데이터',), ('리터러시',), ('함양',), ('위하',...\n1147    [('초등',), ('예비',), ('교사',), ('위하',), ('소프트웨어',...\n1148    [('초등',), ('실',), ('교과서',), ('나',), ('소프트웨어교육'...\nName: kor_full, Length: 1149, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ngrams = tokenized2.apply(lambda row: get_ngrams(row))\n",
    "\n",
    "print(ngrams)\n",
    "#print(type(ngrams))\n",
    "#print(type(ngrams.loc[0]))\n",
    "#print(type(ngrams.loc[0][0]))\n",
    "#ngrams.to_csv('./modi_data/ngrams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get score(l, t)\n",
    "# score = sum_w(p(w|t) * PMI(w,l|c))\n",
    "\n",
    "def get_score(unigram_counter, ngram_candidates, candidate, topic, topic_word_prob, ngram_docs):\n",
    "    def get_pmi(w, l_freq, unigram_counter, docs):\n",
    "        word = \"('\" + w +\"',)\"\n",
    "        count = 0\n",
    "\n",
    "        for doc in docs:\n",
    "            #print(doc)\n",
    "            if word in doc: \n",
    "                count += 1\n",
    "        pmi = count / (unigram_counter.loc[0, w] * l_freq)\n",
    "        return pmi\n",
    "    \n",
    "    candi_docs = []\n",
    "    #print(type(candi_docs))\n",
    "    for doc in ngram_docs:\n",
    "        if candidate in doc:\n",
    "            candi_docs.append(doc)\n",
    "    #print(candi_docs)\n",
    "\n",
    "    for i in range(len(ngram_candidates)):\n",
    "        if ngram_candidates.loc[i, '후보명'] == candidate:\n",
    "            candi_count = ngram_candidates.loc[i, 'count']\n",
    "    #print(candidate, candi_count)\n",
    "\n",
    "    score = 0\n",
    "    for word in unigram_counter.columns:\n",
    "        tw_prob = topic_word_prob.loc[topic, word]\n",
    "        pmi = get_pmi(word, candi_count, unigram_counter, candi_docs)\n",
    "        score += tw_prob * pmi\n",
    "\n",
    "    return round(score * 1000, 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nc = pd.read_excel(\"./modi_data/ngram_candidates.xlsx\")\n",
    "uc = pd.read_excel(\"./modi_data/unigram_counter.xlsx\")\n",
    "nc = nc.drop(['Unnamed: 0'], axis=1)\n",
    "uc = uc.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "#print(nc.columns[0])\n",
    "#print(nc.loc[0, '후보명'])\n",
    "#print(topic_word.loc[0, '교육'])\n",
    "#score1 = get_score(uc, nc, nc.loc[21, '후보명'], 0, topic_word, ngrams)\n",
    "\n",
    "#print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "topic0\n",
      "topic1\n",
      "topic2\n",
      "topic3\n",
      "topic4\n",
      "topic5\n",
      "topic6\n",
      "topic7\n",
      "topic8\n",
      "topic9\n",
      "topic10\n",
      "topic11\n",
      "topic12\n",
      "         0        1        2        3        4        5        6        7   \\\n",
      "0   0.17263  0.22817  0.20887  0.08939  0.52270  0.61278  0.17654  0.50033   \n",
      "1   0.03081  0.18426  0.21663  0.07855  0.98509  0.54752  0.19194  0.37957   \n",
      "2   0.07492  0.42676  0.51182  0.42490  0.47892  0.31328  0.13022  0.85102   \n",
      "3   0.13085  0.31231  0.18703  0.07584  0.43160  0.21659  0.24813  0.40945   \n",
      "4   0.15167  0.20995  0.10571  0.24286  0.55487  1.19974  0.19807  0.46585   \n",
      "5   0.04707  0.07205  0.11746  0.06334  0.54650  0.96316  0.11539  0.36678   \n",
      "6   0.12145  0.25256  0.39088  0.07162  1.02844  0.32443  0.16169  0.55452   \n",
      "7   0.11584  0.31606  0.32396  0.15760  0.46091  0.14183  0.08214  0.50978   \n",
      "8   0.03920  0.28063  0.22725  0.47682  0.66137  0.54381  0.19198  0.47954   \n",
      "9   0.11646  0.22093  0.18979  0.06557  0.47885  0.34552  0.15357  0.46641   \n",
      "10  0.10963  0.21840  0.17108  0.08647  0.51755  0.37831  0.20924  0.49953   \n",
      "11  0.07062  0.70057  0.41451  0.28950  0.65931  1.76346  0.41900  0.28797   \n",
      "12  0.07146  0.36846  0.33282  0.09392  0.44095  0.34967  0.14384  0.46835   \n",
      "\n",
      "         8        9   ...       90       91       92       93       94  \\\n",
      "0   0.30661  0.30012  ...  0.16444  0.43863  0.25448  0.11898  0.10932   \n",
      "1   0.34153  0.59599  ...  0.07933  0.62742  0.06273  0.04215  0.04896   \n",
      "2   0.42590  0.22203  ...  0.05244  0.19497  0.21581  0.27746  0.15092   \n",
      "3   0.41445  0.54431  ...  0.14081  0.36367  0.14851  0.03024  0.09090   \n",
      "4   0.18663  0.13235  ...  0.09635  0.39495  0.12333  0.35443  0.08901   \n",
      "5   0.66844  0.32257  ...  0.04471  0.58434  0.09321  0.04223  0.04400   \n",
      "6   0.23526  0.31773  ...  0.11613  0.32516  0.22437  0.13433  0.09771   \n",
      "7   0.31642  0.26948  ...  0.15456  0.27334  0.33481  0.07692  0.07240   \n",
      "8   0.41985  0.06851  ...  0.02685  0.60134  0.18328  0.26214  0.15152   \n",
      "9   0.23362  0.44373  ...  0.15640  0.28510  0.23660  0.09934  0.08884   \n",
      "10  0.28852  0.54405  ...  0.17451  0.35200  0.14984  0.10873  0.12089   \n",
      "11  0.16682  0.33187  ...  0.09847  0.27465  0.36900  0.21767  0.11181   \n",
      "12  0.29715  0.23365  ...  0.21633  0.44422  0.33852  0.21239  0.07158   \n",
      "\n",
      "         95       96       97       98       99  \n",
      "0   0.50169  0.44382  0.23902  0.59913  0.21012  \n",
      "1   0.36307  0.27570  0.38350  0.36559  0.07261  \n",
      "2   0.64436  0.45361  0.24169  0.42190  0.21651  \n",
      "3   0.40496  0.45842  0.33916  0.28282  0.19208  \n",
      "4   0.41770  0.31423  0.14479  0.51322  0.10665  \n",
      "5   0.32201  0.17791  0.19771  0.52932  0.05977  \n",
      "6   0.51122  0.42918  0.23789  0.35036  0.15607  \n",
      "7   0.66930  0.95606  0.16025  0.31938  0.12966  \n",
      "8   0.51712  0.48342  0.05135  0.50738  0.28097  \n",
      "9   0.59449  0.49710  0.34863  0.41427  0.17829  \n",
      "10  0.44425  0.30047  0.32734  0.36927  0.19831  \n",
      "11  0.55681  0.65202  0.20249  0.32254  0.26573  \n",
      "12  0.74188  0.41303  0.20372  0.35103  0.10171  \n",
      "\n",
      "[13 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# for all topics\n",
    "score_full = pd.DataFrame() # (topic, l_index)\n",
    "for j in range(13): # 11 or 13\n",
    "    score0 = []\n",
    "    for i in range(len(nc)):\n",
    "        score = get_score(uc, nc, nc.loc[i, '후보명'], j, topic_word, ngrams)\n",
    "        score0.append(score)\n",
    "        #score0[nc.loc[i, '후보명']] = score\n",
    "    score_full = score_full.append(pd.Series(score0), ignore_index=True)\n",
    "    #score0 = sorted(score0.items(), key=(lambda x:x[1]), reverse=True)\n",
    "    #score0 = pd.DataFrame.from_dict(score0, orient='index')\n",
    "    #score0.to_excel('./final_data/topic' + str(j) + '_candidates.xlsx')\n",
    "    print('topic'+str(j))\n",
    "\n",
    "print(score_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_full.to_excel('./final_data/topic_full_candidates.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    ('사이버', '가', '정학습')  ('동', '영', '상')  ('애', '플리케이션')  ('로봇', '보조', '학습')  \\\n0              0.154630         0.168788        0.155721            0.053940   \n1              0.010447         0.124146        0.163610            0.042919   \n2              0.055292         0.370687        0.463720            0.395042   \n3              0.112154         0.254330        0.133517            0.040164   \n4              0.133321         0.150264        0.050842            0.209968   \n5              0.026978         0.010066        0.062787            0.027456   \n6              0.102597         0.193584        0.340765            0.035874   \n7              0.096894         0.258142        0.272729            0.123287   \n8              0.018976         0.222122        0.174407            0.447827   \n9              0.097524         0.161427        0.136323            0.029723   \n10             0.090580         0.158855        0.117301            0.050972   \n11             0.050920         0.649061        0.364788            0.257385   \n12             0.051774         0.311416        0.281737            0.058546   \n\n    ('차', '산업', '혁명')  ('대응', '표본', 't')  ('체계', '문헌', '고찰')  \\\n0            0.401961           0.494658            0.139120   \n1            0.872057           0.428310            0.154776   \n2            0.357451           0.190166            0.092028   \n3            0.309342           0.091865            0.211903   \n4            0.434667           1.091401            0.161009   \n5            0.426157           0.850878            0.076951   \n6            0.916130           0.201502            0.124022   \n7            0.339141           0.015859            0.043147   \n8            0.542942           0.424539            0.154817   \n9            0.357380           0.222944            0.115767   \n10           0.396725           0.256280            0.172365   \n11           0.540847           1.664516            0.385621   \n12           0.318848           0.227163            0.105875   \n\n    ('목적', '달성', '위하')  ('computational', 'thinking')  ('정보교육', '학', '회')  \\\n0             0.404684                       0.240034            0.233015   \n1             0.281911                       0.275535            0.533817   \n2             0.761219                       0.361312            0.153624   \n3             0.312289                       0.349671            0.481275   \n4             0.369629                       0.118054            0.062449   \n5             0.268908                       0.607894            0.255840   \n6             0.459777                       0.167494            0.250919   \n7             0.414291                       0.250007            0.201865   \n8             0.383547                       0.355161           -0.002455   \n9             0.370198                       0.165827            0.379019   \n10            0.403870                       0.221642            0.481011   \n11            0.188784                       0.097914            0.265295   \n12            0.372171                       0.230416            0.165438   \n\n    ...  ('통신', '기술', '활용')  ('초점', '맞추')  ('전자', '책')  ('마', '스마트폰', '중독')  \\\n0   ...            0.141825      0.359944     0.213146             0.088013   \n1   ...            0.055297      0.551880     0.018201             0.009902   \n2   ...            0.027958      0.112223     0.173832             0.249134   \n3   ...            0.117801      0.283735     0.105410            -0.002206   \n4   ...            0.072600      0.315536     0.079811             0.327387   \n5   ...            0.020100      0.508082     0.049189             0.009984   \n6   ...            0.092710      0.244583     0.182535             0.103619   \n7   ...            0.131780      0.191899     0.294815             0.045252   \n8   ...            0.001942      0.525366     0.140760             0.233559   \n9   ...            0.133651      0.203855     0.194968             0.068045   \n10  ...            0.152063      0.271870     0.106763             0.077592   \n11  ...            0.074756      0.193231     0.329575             0.188348   \n12  ...            0.194580      0.365627     0.298587             0.182980   \n\n    ('정보', '통신', '윤리')  ('다음', '같')  ('간', '상호', '작용')  ('학습', '방법', '평가')  \\\n0             0.090344     0.398570           0.353634            0.191711   \n1             0.028978     0.257640           0.182712            0.338599   \n2             0.132638     0.543618           0.363587            0.194426   \n3             0.071617     0.300228           0.368478            0.293520   \n4             0.069696     0.313181           0.221884            0.095911   \n5             0.023936     0.215896           0.083292            0.149713   \n6             0.078541     0.408259           0.338750            0.190562   \n7             0.052809     0.568974           0.874412            0.111628   \n8             0.133248     0.414258           0.393894            0.000913   \n9             0.069523     0.492917           0.407802            0.303148   \n10            0.102107     0.340173           0.207895            0.281503   \n11            0.092876     0.454609           0.565304            0.154573   \n12            0.051975     0.642764           0.322331            0.155823   \n\n    ('학년', '학생', '명')  ('통신', '윤리', '의식')  \n0            0.520012            0.177481  \n1            0.282580            0.037679  \n2            0.339828            0.183977  \n3            0.198430            0.159140  \n4            0.432670            0.072286  \n5            0.449039            0.024625  \n6            0.267096            0.122530  \n7            0.235599            0.095680  \n8            0.426733            0.249511  \n9            0.332071            0.145120  \n10           0.286321            0.165474  \n11           0.238812            0.234018  \n12           0.267777            0.067264  \n\n[13 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# score'(l,t) = score(l,t) - alpha(변별성계수) * avg(score(l, t제외))\n",
    "alpha = 0.2\n",
    "score_final = pd.DataFrame() # (t, l)\n",
    "\n",
    "for i in range(len(nc)):\n",
    "    score_ = []\n",
    "    for t in range(13): # 11 or 13\n",
    "        score = score_full.loc[t, i] #score(l, t)\n",
    "        score_list = [s for j, s in enumerate(score_full[i]) if j != t]\n",
    "        avg = sum(score_list) / len(score_list)\n",
    "        score_.append(score - alpha * avg)\n",
    "    score_final[nc.loc[i, '후보명']] = score_\n",
    "print(score_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    #print(score_final.loc[i]) #(100, 1)\n",
    "    s = score_final.loc[i].sort_values(axis=0, ascending=False)\n",
    "    #print(s)\n",
    "    s.to_excel('./final_data/topic' + str(i) + '_candidates.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get score(l, t)\n",
    "# score = sum_w(p(w|t) * PMI(w,l|c))\n",
    "\"\"\"\n",
    "def get_score(unigram_counter, ngram_candidates, candidate, topic, topic_word_prob, ngram_docs):\n",
    "    def get_pmi(w, l, l_freq, unigram_counter, docs):\n",
    "        word = \"('\" + w +\"',)\"\n",
    "        #print(word)\n",
    "        count = 0\n",
    "\n",
    "        for doc in docs:\n",
    "            #print(doc)\n",
    "            if word in doc and l in doc:#and word in doc:\n",
    "                #print('yesss')\n",
    "                count += 1\n",
    "\n",
    "        pmi = count / (unigram_counter.loc[0, w] * l_freq)\n",
    "        return pmi\n",
    "    \n",
    "    for i in range(len(ngram_candidates)):\n",
    "        if ngram_candidates.loc[i, '후보명'] == candidate:\n",
    "            candi_count = ngram_candidates.loc[i, 'count']\n",
    "    print(candidate, candi_count)\n",
    "\n",
    "    score = 0\n",
    "    for word in unigram_counter.columns:\n",
    "        tw_prob = topic_word_prob.loc[topic, word]\n",
    "        pmi = get_pmi(word, candidate, candi_count, unigram_counter, ngram_docs)\n",
    "        score += tw_prob * pmi\n",
    "\n",
    "    return score\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "ModuleNotFoundError",
     "traceback": [
      "Error: ModuleNotFoundError",
      "at b.parseConnectInfo (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:486235)",
      "at b.connectToLocal (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:486838)",
      "at async b.connect (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:484715)",
      "at async b.startDebugSession (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:49:483862)",
      "at async k.submitCode (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:32:585464)",
      "at async k.handleRunByLine (/Users/uni613/.vscode/extensions/ms-toolsai.jupyter-2020.12.414227025/out/client/extension.js:9:173871)"
     ]
    }
   ],
   "source": [
    "# get PMI(word, 후보명(l)|문맥(c))\n",
    "# PMI = (#(w,l)) / (#w * #l)\n",
    "\"\"\"\n",
    "def get_pmi(unigram_counter, ngram_candidates, ngram_docs):\n",
    "    dfPMI = pd.DataFrame()\n",
    "    pmi_list = []\n",
    "\n",
    "    def get_wl_count(word, candidate, docs):\n",
    "        word = '(' + word + ',)'\n",
    "        count = 0\n",
    "\n",
    "        for doc in docs:\n",
    "            if candidate in doc and word in doc:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    for i, l in enumerate(ngram_candidates['후보명']):\n",
    "        for w in unigram_counter.columns:\n",
    "            pmi = get_wl_count(w, l, ngram_docs) / (unigram_counter.loc[0, w] * ngram_candidates.loc[i, 'count'])\n",
    "            pmi_list.append(pmi) \n",
    "            print('word')   \n",
    "        dfPMI.append(pmi_list)\n",
    "        pmi_list = []\n",
    "        print('5000')\n",
    "\n",
    "    dfPMI.columns = unigram_counter.columns\n",
    "\n",
    "    return dfPMI\n",
    "    \"\"\""
   ]
  }
 ]
}